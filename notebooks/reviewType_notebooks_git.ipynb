{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72783,"status":"ok","timestamp":1660754032432,"user":{"displayName":"suwasit wittawijugbbt","userId":"09267968935034910060"},"user_tz":-420},"id":"lzCFmzpOjklG","outputId":"cddfe61c-0345-4602-d6cf-8425260435a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Wed Aug 17 16:33:02 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 57.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 71.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 13.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (3.0.10)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting altair_saver\n","  Downloading altair_saver-0.5.0-py3-none-any.whl (89 kB)\n","\u001b[K     |████████████████████████████████| 89 kB 3.6 MB/s \n","\u001b[?25hRequirement already satisfied: altair in /usr/local/lib/python3.7/dist-packages (from altair_saver) (4.2.0)\n","Collecting selenium\n","  Downloading selenium-4.4.0-py3-none-any.whl (985 kB)\n","\u001b[K     |████████████████████████████████| 985 kB 22.5 MB/s \n","\u001b[?25hCollecting altair-data-server>=0.4.0\n","  Downloading altair_data_server-0.4.1-py3-none-any.whl (12 kB)\n","Collecting altair-viewer\n","  Downloading altair_viewer-0.4.0-py3-none-any.whl (844 kB)\n","\u001b[K     |████████████████████████████████| 844 kB 64.5 MB/s \n","\u001b[?25hRequirement already satisfied: portpicker in /usr/local/lib/python3.7/dist-packages (from altair-data-server>=0.4.0->altair_saver) (1.3.9)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from altair-data-server>=0.4.0->altair_saver) (5.1.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair->altair_saver) (2.11.3)\n","Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.7/dist-packages (from altair->altair_saver) (1.3.5)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair->altair_saver) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair->altair_saver) (4.3.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from altair->altair_saver) (1.21.6)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair->altair_saver) (0.12.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair->altair_saver) (5.9.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair->altair_saver) (22.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair->altair_saver) (0.18.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair->altair_saver) (4.1.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair->altair_saver) (4.12.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair->altair_saver) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->altair->altair_saver) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->altair->altair_saver) (2022.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18->altair->altair_saver) (1.15.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair->altair_saver) (2.0.1)\n","Collecting trio~=0.17\n","  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n","\u001b[K     |████████████████████████████████| 358 kB 65.4 MB/s \n","\u001b[?25hCollecting trio-websocket~=0.9\n","  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n","Collecting urllib3[secure,socks]~=1.26\n","  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n","\u001b[K     |████████████████████████████████| 139 kB 74.9 MB/s \n","\u001b[?25hCollecting sniffio\n","  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->altair_saver) (2.10)\n","Collecting outcome\n","  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n","Collecting async-generator>=1.9\n","  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->altair_saver) (2.4.0)\n","Collecting wsproto>=0.14\n","  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->altair_saver) (1.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium->altair_saver) (2022.6.15)\n","Collecting pyOpenSSL>=0.14\n","  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 5.2 MB/s \n","\u001b[?25hCollecting cryptography>=1.3.4\n","  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n","\u001b[K     |████████████████████████████████| 4.1 MB 59.0 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->altair_saver) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium->altair_saver) (2.21)\n","Collecting h11<1,>=0.9.0\n","  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 6.6 MB/s \n","\u001b[?25hInstalling collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, altair-data-server, selenium, altair-viewer, altair-saver\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.11 which is incompatible.\u001b[0m\n","Successfully installed altair-data-server-0.4.1 altair-saver-0.5.0 altair-viewer-0.4.0 async-generator-1.10 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.4.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 urllib3-1.26.11 wsproto-1.1.0\n","\u001b[K\u001b[?25h\n","> canvas@2.9.3 install /content/node_modules/canvas\n","> node-pre-gyp install --fallback-to-build --update-binary\n","\n","[canvas] Success: \"/content/node_modules/canvas/build/Release/canvas.node\" is installed via remote\n","\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n","\u001b[0m\n","+ canvas@2.9.3\n","+ vega-lite@5.5.0\n","+ vega-cli@5.22.1\n","added 141 packages from 81 contributors and audited 141 packages in 19.96s\n","\n","8 packages are looking for funding\n","  run `npm fund` for details\n","\n","found \u001b[92m0\u001b[0m vulnerabilities\n","\n","\u001b[K\u001b[?25h"]}],"source":["#colab set up enviroment \n","from google.colab import drive\n","drive.mount('/content/drive')\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","\n","!pip install transformers\n","!pip install torch\n","!pip install openpyxl\n","!pip install  altair_saver\n","!npm install vega-lite vega-cli canvas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s-0Mw-0XlXlX"},"outputs":[],"source":["\n","\n","path_src_data='src/data/'\n","path_src_models='src/models/'\n","path_visualization='src/visualization/'\n","path_data_raw='data/raw/'\n","path_data_processed='data/processed/'\n","path_data_interim='data/interim/'\n","path_data_external ='data/external/'\n","path_data_final ='data/final/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QshFk7Mps5VX"},"outputs":[],"source":["import pandas as pd\n","pd.options.mode.chained_assignment = None\n","import numpy as np\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, ConfusionMatrixDisplay\n","from sklearn.model_selection import train_test_split\n","import pickle\n","import matplotlib.pyplot as plt\n","import random\n","from sklearn.metrics import f1_score\n","import torch as torch\n","from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n","from tqdm.notebook import tqdm\n","import altair as alt\n","from altair_saver import save\n","import warnings\n","import torch\n","from transformers import BertForSequenceClassification, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n","from transformers import BertTokenizer, logging\n","from transformers import AutoModel, AutoTokenizer\n","alt.renderers.enable('default')\n","\n","\n","warnings.filterwarnings('ignore')\n","no_deprecation_warning=True\n","\n","\n","\n","\n","MAX_LEN = 768\n","RANDOM_SEED = 42\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed_all(RANDOM_SEED)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","label_dict={'Product':0, 'Quality':1, 'Logistic':2, 'Sale':3, 'Service':4}\n","label_dict_inverse = {v: k for k, v in label_dict.items()}\n","\n","\n","def import_review_data(df, sheet_name):\n","    df = pd.read_excel(\n","                        df,\n","                        engine='openpyxl',\n","                        sheet_name=sheet_name,\n","                        skiprows=0).rename(columns = {'Review Content' : 'content', 'Comment Type 1' : 'topics', 'Comment classified Type 1' : 'sentiment'})\n","\n","    return df\n","\n","\n","\n","def oversample_minority_class(df):\n","\n","  print('original_shape',df.shape)\n","  df['content'] = df['content'].str.lower()\n","  df = df[['content', 'topics', 'sentiment']].dropna()\n","\n","  class_names = list(df.topics.unique())\n","  def to_numeric(labels):\n","    return class_names.index(labels)\n","\n","  possible_labels = df.topics.unique()\n","  label_dict = {}\n","\n","  for index, possible_label in enumerate(possible_labels):\n","      label_dict[possible_label] = index\n","\n","  df['labels'] = df.topics.apply(to_numeric)\n","  col_name1=df.columns\n","  add_3=  random.choices (df[df['labels']==3].values, k=1800)\n","  add_3_df = pd.DataFrame( add_3,columns=col_name1)\n","  add_4=  random.choices (df[df['labels']==4].values, k=1800)\n","  add_4_df = pd.DataFrame( add_4,columns=col_name1)\n","  df1=pd.concat([df, add_3_df, add_4_df], axis=0)\n","\n","  print('oversample_shape', df1.shape)\n","\n","  df=df1\n","\n","  return df\n","\n","\n","def add_label_to_df(df):\n","    label_dict = {'positive': 2, 'neutral': 1, 'negative': 0}\n","    df['label'] = df['emotion'].replace(label_dict)\n","    df = df[['index', 'Vietnamese', 'emotion', 'label']]\n","    return df\n","\n","\n","\n","\n","def data_split(df):\n","  split_seed = 1\n","  df_train, df_test = train_test_split(df, test_size=0.2, random_state=split_seed)\n","  df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=split_seed)\n","  return df_train,df_val,df_test\n","\n","\n","\n","def set_data_category_in_df(df):\n","    df_train,df_val,df_test = data_split(df)\n","    df_train['data_category'] = 'train'\n","    df_test['data_category'] = 'test'\n","    df_val['data_category'] = 'val'\n","    df= pd.concat([df_train,df_test,df_val], axis=0)\n","    print(df.head(5))\n","    return df\n","\n","\n","\n","def encode_data_and_prepare_dataset(df, tokenizer):\n","    df = set_data_category_in_df(df)\n","    encoded_data_train = tokenizer.batch_encode_plus(df[df.data_category == 'train'].Vietnamese.values,\n","                                                     add_special_tokens=True,\n","                                                     return_attention_mask=True,\n","                                                     padding=True,\n","                                                     return_tensors='pt')\n","\n","    encoded_data_val = tokenizer.batch_encode_plus(df[df.data_category == 'val'].Vietnamese.values,\n","                                                   add_special_tokens=True,\n","                                                   return_attention_mask=True,\n","                                                   padding=True,\n","                                                   return_tensors='pt')\n","\n","    input_ids_train = encoded_data_train['input_ids']\n","    attention_masks_train = encoded_data_train['attention_mask']\n","    labels_train = torch.tensor(df[df.data_category == 'train']['label'].values)\n","\n","    input_ids_val = encoded_data_val['input_ids']\n","    attention_masks_val = encoded_data_val['attention_mask']\n","    labels_val = torch.tensor(df[df.data_category == 'val']['label'].values)\n","\n","    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","    return dataset_train, dataset_val\n","\n","\n","\n","def build_Bert_model(pre_trained_model, attention_probs_dropout_prob, hidden_dropout_prob):    \n","    label_dict={'Product':0, 'Quality':1, 'Logistic':2, 'Sale':3, 'Service':4}\n","    model = BertForSequenceClassification.from_pretrained(\n","                                          'vinai/phobert-base', \n","                                          num_labels = len(label_dict),\n","                                          output_attentions = False,\n","                                          output_hidden_states = False,\n","                                          hidden_dropout_prob= hidden_dropout_prob,\n","                                          attention_probs_dropout_prob=attention_probs_dropout_prob,\n","    )\n","                                        )\n","    model = model.to(device)\n","\n","    return model\n","\n","\n","def create_data_loader(df, tokenizer, max_len, batch_size):\n","  encoding = tokenizer.batch_encode_plus(\n","      df.content.to_numpy(),\n","      add_special_tokens=True,\n","      return_token_type_ids=False,\n","      return_attention_mask=True,\n","      padding=True,\n","      return_tensors='pt',\n","      max_length = max_len,\n","      truncation=True\n","    )\n","  dataset = TensorDataset(encoding['input_ids'],encoding['attention_mask'],torch.tensor(df.labels.to_numpy()))\n"," \n","  return DataLoader(\n","    dataset,\n","    sampler=RandomSampler(dataset),\n","    batch_size=batch_size  \n","    )\n","  \n","\n","def setup_optimizer(model, Ir, eps):\n","    optimizer = AdamW(model.parameters(),\n","                      lr=Ir,\n","                      eps=eps)\n","    return optimizer\n","\n","\n","def setup_scheduler(dataloader_train, optimizer, epochs):\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0,\n","                                                num_training_steps=len(dataloader_train) * epochs)\n","    return scheduler\n","\n","\n","def evaluate(model, dataloader_validation):\n","    model.eval()\n","\n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","\n","    for batch in dataloader_validation:\n","        batch = tuple(b.to(device) for b in batch)\n","\n","        inputs = {'input_ids': batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels': batch[2],\n","                  }\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","\n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_val_total += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","\n","    loss_val_avg = loss_val_total / len(dataloader_validation)\n","\n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","\n","    return loss_val_avg, predictions, true_vals\n","\n","\n","def train_model_phobert(model, model_path ,pre_trained_model, model_type, Ir, eps, attention_probs_dropout_prob, hidden_dropout_prob, epochs,\n","                batch_size, dataloader_train, dataloader_validation, train_data_provider):\n","  tmp_loss = float('inf')\n","  epoch_list=[]\n","  train_loss=[]\n","  validation_loss=[]\n","  F1_score_weighted=[]\n","  F1_score_macro=[]\n","  F1_score_micro=[]\n","  optimizer1 = setup_optimizer(model, Ir, eps)\n","  for epoch in tqdm(range(1, epochs+1)):\n","      epoch_list.append(epoch)\n","      model.train()\n","      loss_train_total = 0\n","      \n","      progress_bar = tqdm(dataloader_train, \n","                          desc='Epoch {:1d}'.format(epoch), \n","                          leave=False, \n","                          disable=False)\n","      \n","      for batch in progress_bar:\n","          model.zero_grad()\n","          batch = tuple(b.to(device) for b in batch)\n","          inputs = {\n","              'input_ids': batch[0],\n","              'attention_mask': batch[1],\n","              'labels': batch[2]\n","          }\n","          \n","          outputs = model(**inputs)\n","          loss = outputs[0]\n","          loss_train_total +=loss.item()\n","          loss.backward()\n","          \n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","          optimizer1.step()\n","\n","          \n","          progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n","      \n","\n","      \n","      tqdm.write('\\nEpoch {epoch}')\n","      \n","      loss_train_avg = loss_train_total/len(dataloader_train)\n","      \n","      val_loss, predictions, true_vals = evaluate(model,dataloader_validation)\n","      val_f1_weighted = f1_score_func(predictions, true_vals,'weighted')\n","      val_f1_macro = f1_score_func(predictions, true_vals,'macro')\n","      val_f1_micro = f1_score_func(predictions, true_vals,'micro')\n","\n","      train_loss.append(loss_train_avg)\n","      validation_loss.append(val_loss)\n","      F1_score_weighted.append(val_f1_weighted)\n","      F1_score_macro.append(val_f1_macro)\n","      F1_score_micro.append(val_f1_micro)\n","\n","      if val_loss < tmp_loss:\n","        print('Save Model -----------------')\n","        torch.save(model, model_path)\n","        tmp_loss = val_loss\n","\n","      \n","\n","      tqdm.write(f'Training loss: {loss_train_avg}')\n","      tqdm.write(f'Validation loss: {val_loss}')\n","      tqdm.write(f'F1 Score (weighted): {val_f1_weighted}')\n","      tqdm.write(f'F1 Score (macro): {val_f1_macro}')\n","      tqdm.write(f'F1 Score (micro): {val_f1_micro}')\n","\n","      eval_df=pd.DataFrame()\n","      eval_df['epoch'] = epoch_list\n","      eval_df['train_loss'] = train_loss\n","      eval_df['val_loss'] = validation_loss\n","      eval_df['F1_score_weighted'] = F1_score_weighted\n","      eval_df['F1_score_macro'] = F1_score_macro\n","      eval_df['F1_score_micro'] = F1_score_micro\n","      eval_df['batch_size'] = batch_size\n","      eval_df['Ir'] = Ir\n","      eval_df['eps'] = eps\n","      eval_df['pre_trained_model'] = pre_trained_model\n","      eval_df['hidden_dropout_prob'] = hidden_dropout_prob\n","      eval_df['attention_probs_dropout_prob'] = attention_probs_dropout_prob\n","      eval_df['note'] = 'Added and splited Self-judged Review emotions into train and valiation by 8:2'\n","      eval_df['train_data_creator'] = train_data_provider \n","\n","  return eval_df, model\n","\n","\n","\n","\n","\n","def f1_score_func(preds, labels, average):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average=average)\n","\n","\n","def accuracy_per_class(preds, labels, model_type, epochs, train_data_provider):\n","    class_list = []\n","    score_list = []\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    print(\"Prediction accuracy for individual class:\")\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat == label]\n","        y_true = labels_flat[labels_flat == label]\n","        acc = len(y_preds[y_preds == label]) / len(y_true)\n","        class_list.append(label_dict_inverse[label])\n","        score_list.append(len(y_preds[y_preds == label]) / len(y_true))\n","        print(f'Class: {label_dict_inverse[label]}')\n","        print(f'Accuracy: {len(y_preds[y_preds == label])}/{len(y_true)}, ', \\\n","              '{:.3f}'.format(acc), '\\n')\n","    df = pd.DataFrame(class_list, columns=['class'])\n","    df['score'] = score_list\n","    df['pre_trained_model'] = model_type\n","    df['epoch'] = epochs\n","    df['train_data_creator'] = train_data_provider\n","    return df\n","\n","\n","def predict_text(input_text, tokenizer, model):\n","    inputs = tokenizer(input_text.lower(), return_tensors=\"pt\").to(device)\n","    with torch.no_grad():\n","        logits = model(**inputs).logits\n","    predicted_class_id = logits.argmax().item()\n","    return label_dict_inverse[predicted_class_id]\n","\n","\n","def prepare_review_data(review_df):\n","    review_df = review_df.reset_index()\n","    review_df_1 = review_df[['index', 'Review Content', 'Rating']].dropna(how='any')\n","    print(\"raw review dataset after dropping null value:\", review_df_1.shape)\n","    return review_df, review_df_1\n","\n","def generate_predition_data(df):\n","    review_df, review_df1 = prepare_review_data(df)\n","    review_df1['emotion'] = review_df1['Review Content'].apply(predict_text)\n","    review_emotion_prediction = pd.merge(review_df, review_df1[['index', 'emotion']], how='left', on='index')\n","    return review_emotion_prediction\n","\n","\n","\n","\n","def draw_F1_scores(df, domain, width, height, first_line_title, second_line_title, epochs):\n","    if epochs == 1:\n","        base = alt.Chart(df).mark_point()\n","    else:\n","        base = alt.Chart(df).mark_line()\n","\n","    graph = base.encode(\n","        x='epoch',\n","        y=alt.Y(\"value:Q\", title=\"\", scale=alt.Scale(domain=domain)),\n","        color=alt.Color('line type:N',\n","                        legend=alt.Legend(\n","                            title=\"Metrics\",\n","                            orient='right',\n","                            titleFontSize=11,\n","                            titleColor='black',\n","                            labelFontSize=10.5,\n","                            labelColor='black',\n","                            direction='vertical')),\n","        tooltip=['emotion', 'epoch', 'line type', 'value']\n","    ).interactive(\n","    ).properties(\n","        width=width,\n","        height=height,\n","        title={\"text\": [first_line_title, second_line_title], \"color\": \"black\"})\n","    return graph\n","\n","\n","def draw_prediction_accuracy(df, domain, width, height, first_line_title, second_line_title):\n","    base = alt.Chart(df).mark_bar().encode(\n","        x=alt.X('class:N', axis=alt.Axis(labelAngle=360))\n","    ).properties(\n","        width=width,\n","        height=height,\n","        title={\"text\": [first_line_title, second_line_title], \"color\": \"black\"})\n","\n","    graph = base.mark_bar(size=20).encode(\n","        y=alt.Y(\"score:Q\", title=\"\", scale=alt.Scale(domain=domain)),\n","        color=alt.Color('class:N', legend=None),\n","        tooltip=['pre_trained_model', 'class', 'score', 'epoch', 'train_data_creator']\n","    ).interactive()\n","    return graph\n","\n","\n","def prepare_data_for_metrics_graphs(df, best_epoch_F1_score_macro, best_model=False):\n","    df_f1_scores_id_vars = ['emotion', 'epoch', 'batch_size', 'Ir', 'eps', 'pre_trained_model', 'hidden_dropout_prob',\n","                            'attention_probs_dropout_prob', 'note', 'train_data_creator']\n","    df_f1_scores_value_vars = ['train_loss', 'val_loss', 'F1_score_weighted', 'F1_score_macro', 'F1_score_micro']\n","\n","\n","    df_f1_scores_var_name = ['line type']\n","    if best_model:\n","        df_f1_scores = df[df['epoch'] <= best_epoch_F1_score_macro]\n","    else:\n","        df_f1_scores = df.copy()\n","    df_f1_scores_long = pd.melt(df_f1_scores,\n","                                id_vars=df_f1_scores_id_vars,\n","                                value_vars=df_f1_scores_value_vars,\n","                                var_name=df_f1_scores_var_name)\n","    return df_f1_scores_long\n","\n","\n","def prepare_metrics_graphs(df_f1_scores_long, df_class_accuracy, domain, width, height, epochs):\n","    F1_scores_graph = draw_F1_scores(df_f1_scores_long,\n","                                     domain,\n","                                     width,\n","                                     height,\n","                                     \"F1 scores (Macro, Micro, Weighted)\",\n","                                     \"Train loss, Validation loss\",\n","                                     epochs)\n","\n","    prediction_accuracy_graph = draw_prediction_accuracy(df_class_accuracy,\n","                                                         domain,\n","                                                         width,\n","                                                         height,\n","                                                         \"Accuracy Per Class\",\n","                                                         \"Pre-Trained Model: \" \\\n","                                                         + df_class_accuracy['pre_trained_model'][1])\n","    return F1_scores_graph, prediction_accuracy_graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xgeyFP8_s17K"},"outputs":[],"source":["def confusion_matrix_function (true_test,predictions):\n","  from sklearn.metrics import multilabel_confusion_matrix\n","  from sklearn.metrics import confusion_matrix\n","\n","  class_list = ['Product', 'Quality', 'Logistic', 'Sale', 'Service']\n","  confusion1= confusion_matrix(true_test, np.argmax(predictions, axis=1).flatten())\n","\n","  ConfusionMatrixDisplay.from_predictions(true_test, np.argmax(predictions, axis=1), cmap= 'Blues', colorbar = False, display_labels = class_list)\n","  plt.tight_layout()\n","  plt.subplots_adjust(wspace = 0.40, hspace = 0.1)\n","  plt.savefig(path_visualization+'confusion_phobert.png')\n","  return confusion1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r-k9ZsMnqHeg"},"outputs":[],"source":["def build_df__phobert_comparision(eval_df):\n","\n","\n","\n","  phobert_df_task1=pd.read_csv(path_data_external+'phobert1_eval_df_.csv')\n","  phobert_df_task1['epoch']=range(1,21)\n","  phobert_df_task1['table id']=1\n","\n","  phobert_df_task2=pd.read_csv(path_data_external+'phobert2_eval_df_.csv')\n","  phobert_df_task2['epoch']=range(1,21)\n","  phobert_df_task2['table id']=2\n","\n","  phobert_df_task3=pd.read_csv(path_data_external+'phobert3_eval_df_.csv')\n","  phobert_df_task3['epoch']=range(1,21)\n","  phobert_df_task3['table id']=3\n","\n","  phobert_df_task4=eval_df\n","  phobert_df_task4['table id']=4\n","\n","  train_pipeline_df=train_pipeline_df.drop(['train_data_creator', 'note'], axis=1)\n","  train_pipeline_df['table id']=5\n","  df_combined=pd.concat([phobert_df_task1,phobert_df_task2,phobert_df_task3,phobert_df_task4,train_pipeline_df ])\n","\n","\n","  df_combined_long=pd.melt(df_combined, id_vars=[ 'epoch','batch_size', 'Ir', 'eps',\n","        'pre_trained_model', 'hidden_dropout_prob',\n","        'attention_probs_dropout_prob',  'table id'], value_vars=['train_loss', 'val_loss', 'F1_score_weighted',\n","        'F1_score_macro', 'F1_score_micro'],var_name=['line type'])\n","\n","  return df_combined_long\n","\n","\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"azPd2o1GqcDl"},"outputs":[],"source":["def draw_graph( df,domain,table_id,width,height,scheme_name, \n","               first_line_title,second_line_title,third_line_title,four_line_title,five_line_title):\n","\n","    df=df[df['table id']==table_id]\n","    base = alt.Chart(df).mark_line().encode(\n","        x='epoch'\n","    ).properties(\n","        width=width,\n","        height=height,\n","        title={\n","          \"text\": [first_line_title,second_line_title,third_line_title,four_line_title,five_line_title], \n","\n","          \"subtitle\": [\"\", \"\"],\n","          \"color\": \"black\",\n","          \"subtitleColor\": \"black\",\n","        'anchor': 'middle',\n","        'fontSize': 15,\n","        'subtitleFontSize': 10,\n","        'offset': 1,\n","        }\n","    )\n","    graph=base.mark_line().encode(\n","        y=alt.Y(\"value:Q\",title=\"\",scale=alt.Scale(domain=domain)),\n","        color=alt.Color('line type:N',\n","                        legend=alt.Legend(\n","                        orient='bottom',\n","                        titleFontSize=11,\n","                        titleColor='black',\n","                        labelFontSize=15,\n","                        labelColor='black',\n","                        direction='horizontal'\n","                        )\n","                       ),\n","        tooltip=['epoch','line type','value']\n","        ).interactive()\n","    return graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_qDaNOcZqwxM"},"outputs":[],"source":["def combined_graph(df):\n","    width=300\n","    height=300\n","    scheme_name='greens'\n","    domain=(0,1.2)\n","    graph1=draw_graph(df,domain,1,width,height,scheme_name,'Model1','Phubert_1', 'Full data','dropout 0.1' ,\"\")\n","    graph2=draw_graph(df,domain,2,width,height,scheme_name,'Model2','Phubert_1', 'Group_class', 'droup 0.1' ,\"\")\n","    graph3=draw_graph(df,domain,3,width,height,scheme_name,'Model3','Phubert_1', 'Remove_class','dropout 0.1' ,\"\")\n","    graph4=draw_graph(df,domain,4,width,height,scheme_name,'Model4','Phubert_1', 'Remove_class','dropout 0.4' ,\"\")\n","\n","    title=alt.Chart({\"values\": [{\"text\": \"Model Evaluation\"}]}).mark_text(\n","    size=15,dx=370,dy=0,color=\"black\").encode(text='text:N').properties(width=width,height=10)\n","    \n","    chart= (graph1 | graph2 | graph3| graph4).configure_view(\n","        stroke=None\n","    ).configure_concat(\n","        spacing=6\n","    ).configure_title(fontSize=10.5)\n","    \n","\n","    return chart\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZyOwhgNwf-A6"},"outputs":[],"source":["def load_accu_to_df(data,method):\n","    load_data = pickle.load(open(data , 'rb'))\n","    data_frame_load= load_data[['algorithms',  'accuracy',\n","           'precision', 'recall', 'f1_score']]\n","    data_frame_load['data_method']= method\n","    data_frame_load['algorithm_method'] = data_frame_load[[\"algorithms\", \"data_method\"]].apply(\"-\".join, axis=1)\n","    return data_frame_load\n","\n","def build_traditional_chart (chart_df ):\n","  base = alt.Chart(chart_df).mark_bar().encode(\n","      x='algorithm_method:N',\n","      y= alt.Y('f1_score:Q', scale=alt.Scale(domain=(0,1.1))),\n","      color= 'algorithms:N',\n","      tooltip=['f1_score']\n","    )\n","      \n","  text= base .mark_text(dy= -10 ).encode(\n","      x='algorithm_method:N',\n","      text= alt.Text( 'f1_score:Q',format='.2f' ),\n","\n","  )\n","\n","  chart= (base+text).properties(width=600).configure_axis(\n","      labelFontSize=15,\n","      titleFontSize=15).interactive()\n","  return chart\n","\n","def compare_tranditional():\n","  performance_df_all = path_data_external+'df__phobert_all.sav'\n","  performance_df_grouped = path_data_external+'df__phobert_grouping.sav'\n","  performance_df_remove = path_data_external+'df_phobert_remove.sav'\n","  performance_df_all_upsampling= path_data_external+'df__phobert_all_upsamples.sav'\n","  traditional_df_all=  path_data_external+'df_predict_all.sav'\n","  traditional_df_upsampling= path_data_external+ 'df_predict_upsampling.sav'\n","  traditional_df_group = path_data_external+'df_predict_grouping.sav'\n","  traditional_df_remove= path_data_external+'df_predict_remove.sav'\n","\n","  model_list=[performance_df_all,performance_df_grouped,performance_df_remove,performance_df_all_upsampling,traditional_df_all,traditional_df_upsampling,traditional_df_group,traditional_df_remove]\n","  method_list=['all','grouped','removed','upsampling','all','upsampling','grouped','removed']\n","\n","  df_out=pd.DataFrame()\n","  for i,model in enumerate(model_list):\n","      df_temp = load_accu_to_df(model,method_list[i])\n","      df_out = pd.concat([df_temp,df_out])\n","\n","  all_model=df_out\n","\n","  chart_df=all_model[all_model['data_method']!='grouped']\n","  return build_traditional_chart (chart_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11322,"status":"ok","timestamp":1660754077745,"user":{"displayName":"suwasit wittawijugbbt","userId":"09267968935034910060"},"user_tz":-420},"id":"H_vGYG5bfs4o","outputId":"5f0fb282-e4b3-4d90-8cea-e85b276ce5cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["original_shape (26612, 19)\n","oversample_shape (15730, 4)\n","                                                 content    topics sentiment  \\\n","6970                           sp tốt, hợp với giá tiền.   Quality      Good   \n","1775   shop làm ăn như shit nha các bạn bán hàng khôn...      Sale       Bad   \n","23459                   hàng rất chất lượng, gói hàng kỹ   Product      Good   \n","17841  hàng rất tuyệt vời, đóng gói cẩn thận. anh shi...  Logistic      Good   \n","17214                      vừa đập hộp xong đã thấy hư r   Quality       Bad   \n","\n","       labels data_category  \n","6970        1         train  \n","1775        3         train  \n","23459       0         train  \n","17841       2         train  \n","17214       1         train  \n"]}],"source":["\n","input_file= path_data_raw+'Reviews.xlsx'\n","import_data = import_review_data(input_file, 'Database_LZD')\n","output_data = oversample_minority_class(import_data)\n","data_category_df = set_data_category_in_df(output_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":467,"referenced_widgets":["d6fcb3d5c5b04c2a8df5b353b0fb0e09","051e43dbb68547758f2fde1e8774d153"]},"executionInfo":{"elapsed":363157,"status":"ok","timestamp":1660754450331,"user":{"displayName":"suwasit wittawijugbbt","userId":"09267968935034910060"},"user_tz":-420},"id":"mwR-TsrnhVxc","outputId":"3394b82c-a322-4294-c8e1-c0289158958a"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at vinai/phobert-base were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.2.output.dense.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'lm_head.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['encoder.layer.0.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'classifier.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'pooler.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'classifier.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'pooler.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6fcb3d5c5b04c2a8df5b353b0fb0e09","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"051e43dbb68547758f2fde1e8774d153","version_major":2,"version_minor":0},"text/plain":["Epoch 1:   0%|          | 0/1259 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Epoch {epoch}\n","Save Model -----------------\n","Training loss: 0.8474015363205796\n","Validation loss: 0.47827436642514337\n","F1 Score (weighted): 0.8292918665355007\n","F1 Score (macro): 0.8150092037149514\n","F1 Score (micro): 0.833134684147795\n"]}],"source":["#reviewType_train_phobert\n","\n","MAX_LEN = 256\n","RANDOM_SEED = 42\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed_all(RANDOM_SEED)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","hidden_dropout_prob = 0.4\n","attention_probs_dropout_prob = 0.1\n","pre_trained_model = 'vinai/phobert-base'\n","model_type = pre_trained_model.split('/')[0]\n","batch_size = 8\n","epochs = 1\n","Ir = 1e-5\n","eps = 1e-8\n","train_data_provider = 'Suwasit'\n","\n","reviews_label_df = data_category_df \n","df_train=reviews_label_df[reviews_label_df.data_category=='train']\n","df_test=reviews_label_df[reviews_label_df.data_category=='test']\n","df_val=reviews_label_df[reviews_label_df.data_category=='val']\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n","\n","dataloader_train= create_data_loader(df_train, tokenizer, MAX_LEN, batch_size)\n","dataloader_validation = create_data_loader(df_val, tokenizer, MAX_LEN, batch_size)\n","dataloader_test = create_data_loader(df_test, tokenizer, MAX_LEN, batch_size)\n","\n","model = build_Bert_model(pre_trained_model, attention_probs_dropout_prob, hidden_dropout_prob)\n","model_path =  path_data_final+'reviewtype_phobert_model.pt'\n","torch.save(model.state_dict(), model_path)\n","\n","eval_df, model = train_model_phobert(model, model_path,pre_trained_model, model_type, Ir, eps, attention_probs_dropout_prob, hidden_dropout_prob,\n","                                  epochs, batch_size, dataloader_train, dataloader_validation, train_data_provider)\n","eval_df_path = path_data_interim=+'reviewtype_pho_bert_eval_df.csv'\n","eval_df.to_csv(eval_df_path , index=False)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":675},"executionInfo":{"elapsed":26825,"status":"ok","timestamp":1660755350700,"user":{"displayName":"suwasit wittawijugbbt","userId":"09267968935034910060"},"user_tz":-420},"id":"sDdyNXRehv8S","outputId":"475fa105-2c8a-4687-b7f4-5a04dd91ab27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Prediction accuracy for individual class:\n","Class: Product\n","Accuracy: 1078/1158,  0.931 \n","\n","Class: Quality\n","Accuracy: 683/834,  0.819 \n","\n","Class: Logistic\n","Accuracy: 310/385,  0.805 \n","\n","Class: Sale\n","Accuracy: 337/371,  0.908 \n","\n","Class: Service\n","Accuracy: 327/398,  0.822 \n","\n","[[1078   60   16    3    1]\n"," [  66  683   79    2    4]\n"," [  49   24  310    0    2]\n"," [   8   26    0  337    0]\n"," [   5    5   58    3  327]]\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAATQAAAEYCAYAAADS7wrSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gU5drH8e+dRkINJYQgJUjvCEEEBGmiKIJYjgoClmNBAbtHbCh2ffWgInhABQsqFlREQBSlI70jSDsighA6CSXJ7v3+MUMIMZ0km8y5P9fFxezslHt2N7995pmdGVFVjDHGC4ICXYAxxuQXCzRjjGdYoBljPMMCzRjjGRZoxhjPCAl0AUWFhESohJUJdBl50qxB9UCXkGdBIoEuIc+Kb+XF34oVy/epalT68RZoLgkrQ4n6/wh0GXkya+7IQJeQZ+FhwYEuIc+CgyzSAiUiVH7PaLztchpjPMMCzRjjGRZoxhjPsEAzxniGBZoxxjMs0IwxnmGBZozxDAs0Y4xnWKAZYzzDAs0Y4xkWaMYYz7BAM8Z4hgWaMcYzLNCMMZ5hgWaM8QwLNGOMZ1igGWM8wwLNGOMZdgnuPHrziX5ccmET9h08SrvrnwcgsmxJ3nv+FmrEVGDH7gPcPOxdDh89zpAbu3Jtj9YAhAQHUS+2CnW6P8KhI8cYdENn+l/ZDlTZsGUXd4/4iJNJKQHbrsNHj/HQS5PYtH03IvDqIzdwbo3K3DX8ff746wDVq1RgzIibiCxTMmA1ZmboMxOZuWAdlcqXYf4nj6aOH/fZHN79Yi7BQUFc3L4xTw25MoBVZu/EyWQuv30kJ5NT8KX46NX1PIbdcXmgy8qRwSM+4vv5znuwaNJjhb7+AmuhiYhPRFaJyDoR+VxE8vwXICKzRSQuD/NFishdeV1vVj6Z+gvXDH3rjHH3DbyYuUs3EXf1COYu3cR9A7sD8OZHs+jY70U69nuREW9NYcGKzRw6coyYqHLccd1FdBnwMu2uf56goCCu6t6qIMrNseFvfEWnNg2YM/FRZo5/mDo1o3nro1m0b1WP+Z88TvtW9Xjrox8DWmNmru/Zhkkjz3y75y37jelz1zDno0dY8Olj3N2va4Cqy7kSYSF8M2Yo8z8extyPhzFr0QaWrt0e6LJy5IaeF/DFG3cHbP0Fuct5XFVbqGoTIAm4M+2TIlIYrcNIoEACbeHKrRw8cuyMcT0uasYnUxcD8MnUxVzWqdnf5ru6exxfzlye+jgkJJjwEqEEBwdRMjyMv+IPF0S5OXIk4TiLV2/lhp4XABAWGkK5MiWZOX8t117qtDCvvbQ1389bG7Aas9LuvDqUL3vm9+aEyfO5Z8DFlAgLBSCqQtG/s5eIULpkCQCSU3wkp/iQYnJ3rPYt//4eFKbC6kObB9QRkU4iMk9EpgAbRCRcRMaLyFoRWSkinQFEJEJEPhWRX0XkKyDi1IJEJCHN8DUiMsEdjhaRr0RktfuvHfAiUNttKb5S0BtZuUIZ9uw/AsCe/UeonO6PJ6JEKF3bNmTKT6sA2B1/mDc/msXab59h4/TnOJJ4nJ8XbyzoMjP1x+79VIgszf3Pf8wlt7zCgy9+yrHjJ9l38CjRlcoBULliWfYdPBqwGnNr6469LFq1le63/B9X3Pk6KzZkeLOgIsfn89Oh7wvU6/4Indo0IK5JbKBLKhYKPNDcllgP4NTXekvgHlWtB9wNqKo2BW4A3heRcGAQcExVGwLDgZzsh70BzFHV5u461gOPAFvdluJDGdR2u4gsE5FlmnL87DY0A6pnPr60Y1MWr9nGIbdlV65MBJd1bEqL3sNp2OMxSoaH8Q+3ry0QUnx+1v22k/5Xtuf79x6iZEQYb02cdcY0IoIUoztSpvj8HDpyjO/ffYCnh/Tmn4++h6Z/Y4qg4OAg5n08jPXfPcuK9b+zYcuuQJdULBRkoEWIyCpgGbADeNcdv0RVT3UIXAh8BKCqG4HfgXpAxzTj1wBrcrC+LsAYdx6fqma776aqY1U1TlXjJCQiu8mztffAUaIrlgUgumJZ4tO1ZK66uBVffn96d7PT+Q34fdd+9h9KIMXn59ufV3N+s1pnXUdexURFEhNVjpaNYwG4vFNz1m7aSaXyZdizz3k59+w7TMXypQNWY25VrRzJ5Z2aIyK0bBxLUFAQ+w8lZD9jEVGuTEk6tKrHrEUbAl1KsVAYfWgtVHWIqia54xPPcrlpv17Dz3JZ+WrG3LXc0LMNADf0bMP0OadzuGypcNq3rMO0NON2/nWAuKa1iCjh9O9c1Lo+m7bvKdyi06hcsSxVK5dn6w6nhvnLf6NubDQXt2/C5zOWAvD5jKV0v7BpwGrMrR4XNWP+8s0AbNmxl6TkFCpGFu1A3nfwKIePOq344yeS+HnJRurGRge4quIh0D/bmAf0A34SkXpADWATMBfo645vAqTtXd8jIg3d6foAp5pBs3B2VUeKSDBQ2n2uQHqB33n2Jtq3qkvFyNKsm/oML46dxr/f/4HxL9zCjb3a8sdfB7h52Hup01/euTk/L97IsRNJqeOWr/+dKbNWMvujf+Hz+VmzaSfvf7WgIMrNsWfuvYohIz4iKTmFmlUr8uqjfVG/cueTE/j0u1+oFl2BMSMGBrTGzNz2+HgWrNjCgUMJNO35BP+6/TL6XXEBQ5+dyIU3PE9oaDCjht9Y5DvY/9p3hLue+hCf34/fr/Tp1pJLOxSPL5FbHxvPguWb2X8ogcaXP84jt19G/97tCm39UlD9CSKSoKql043rBDyoqj3dx+E4u4lxQApwv6r+LCIRwHigOfArcA5wt6ouE5FrgJeAeJzd2dKqepOIRANjgXMBHzBIVReJyMc4gTg9o360U4JKVtYS9f+Rj69A4dk5b2SgS8iz8LDgQJeQZ8FBRTsYvSwiVJar6t9+ylVggVbcWKAFhgWayYvMAs1OfTLGeIYFmjHGMyzQjDGeYYFmjPEMCzRjjGdYoBljPMMCzRjjGRZoxhjPsEAzxniGBZoxxjMs0IwxnmGBZozxDAs0Y4xnWKAZYzzDAs0Y4xkWaMYYz7BAM8Z4RqDvKVBkNGtQnR/nFs8rv179zuJAl5Bnk245P9Al5Fm5kqGBLsGkYy00Y4xnWKAZYzzDAs0Y4xkWaMYYz7BAM8Z4hgWaMcYzLNCMMZ5hgWaM8QwLNGOMZ1igGWM8wwLNGOMZFmjGGM+wQDPGeIYFmjHGMyzQjDGeYYFmjPEMCzRjjGdYoBljPMMCzRjjGXZPgQJw+OgxHn5pEpu270YE/u+RG2jVpBbjv5jL+1/NJzgoiC5tG/HYXb0CXSoApcKCubdLHWIrlkQV/v3TFk6m+BnSqTZhwYJPYdTsrfy2N4ELalVgYJsa+FXxKfxn3jbW7z4a6E1g6469DH76/dTHf+zaz3239KDteXV47NXPOXY8iWpVyjPyif6UKRUewEqzt/Ovgwx66gPiDxxFgIF92nPnDZ0DXVaO+Xx+Og94mZjK5Zj070GFuu5CCTQRqQa8BTQCgoFpwAOqejIPy5oNPKiqy0RkGtDXfaqvqo7Op5LPylNvfEWnNg34z7M3k5ScwvETSSxcsZmZ89fx/fiHKREWwr6DgQ+BU+7seC7LdxziuRmbCAkSSoQE8eil9Zm4ZAfLdhyidc3y/LN9LA9/tY5VOw/xy/YDANSqWJJHL63PbRNXBngLoHaNykx/9yHA+YNqc81TXNKhKXc9OYFH7+rFBS3q8Nl3ixn76U88cOtlAa42ayEhQTx771U0b1Cdo4kn6DzgJTq1aUCDc2MCXVqOvP3pz9SrFc3RxBOFvu4C3+UUEQEmA1+ral2gLhABvHy2y1bVy1T1EBAJ3HW2y8sPRxKOs3j1Vq7veQEAYaEhlCtTkg+/XsBdN3alRJjzHVKpfJlAlpmqZFgwTauWZcaGPQCk+JXEJJ/7nFNrqbBg9icmAXAi2Z86b3hoMKqFXHAOLFjxGzWrVqRalQps3xlPm+a1AbiwdT2mz1kT4OqyV6VSOZo3qA5AmVLh1Iutwu74QwGuKmf+3HOQmfPXM6B3u4CsvzBaaF2AE6o6HkBVfSJyH/C7iGwGGqjqYAARmQr8n6rOFpExQGuc8PtCVYenX7CI/BeIA14EaovIKuAHIBqYrKpfu9NNBD5T1W8KeFv5Y/d+KkSW5v7nP+bXrbtoWq86T9/Th21/7GXJ6m28PPY7SoSF8vjdvWnRsEZBl5OtKmXDOXw8mQe61qFWpVJs2ZvImHnbeHvedp7r1Zjb2sciAvd/uTZ1nnbnVuDmtjWJjAjlyam/BrD6jH07ayW9urYEoG5sFWbOX8clHZoy7efV7N5bPILhlB279rNm005aNY4NdCk58uhrX/L00CtJOFb4rTMonIMCjYHlaUeo6hHgv2QdqI+pahzQDLhIRJplMe0jwFZVbaGqDwHvAjcBiEg5oB3wXfqZROR2EVkmIsv279uX8y3KQorPz7rfdjLgyvbMeO8hSkaE8dbEWaT4/Bw6cowp/7mPx+7qxV3DJ6BFoHkTHCTUiSrN1HV/MXjSak6k+LiuVTV6NqnCf+Zvp//7y/jP/O3c16VO6jwLtx3gtokreXraRga0CXwop5WUnMKPC9dzWacWALz8r+v56Ov59LztVRKOnyA0NDjAFeZcwrGTDPjXO7xw/9WULR0R6HKyNWPeWiqVLxPQL+qifJTzHyKyAliJE4qNcjqjqs4B6opIFHAD8KWqpmQw3VhVjVPVuIqVKuVL0TFRkcREleM89xv1sk7NWbdpJzFRkfS4qBkiwnmNaiIiHDiUmC/rPBv7Ek6yL+Ekm/YkADBvy37qRJWiW4PKLNi6P3VcvejSf5t33a4jVCkbTtnwonNsafbiX2lS9xyiKji79HVqRvPhq4OYOu4BenVtSc2q+fM+F7TkFB8D/zWOay+N44ouLQJdTo4sXr2NGfPW0qzXk9z66HjmLf2N2594P/sZ81FhBNoGoFXaESJSFqgC7E9XQ7j7fC3gQaCrqjbDaV3l9tDUB8CNwM3Ae3mqPA8qVyxLTOXybN3h9EktWP4bdWOjuaRDUxau2AzAth17SU7xUSGyVGGVlamDx5KJTzhJtUinBXBe9XLsOHCc/YlJNDunLAAtqpVj1yFnFyKm3Om3oU5UKUKDhSMn/vZdETBTZq3kCnd3E0g9+OL3+xn1wQ/06xWYvp3cUFWGPDORerFVuLtf10CXk2PDB/dm/XfPsmbKCN59/mY6tK7H2GcGFmoNhfHVOgt4UUQGqOoHIhIMvAqMArYDg0QkCDgHON+dpyyQCBwWkWigBzA7i3UcBdL3sk8AlgB/qeqGfNqWHHnm3qsYMuIjkpNTqFG1Iq8+2peS4WE8+MIndB3wImEhIfz70b44x0sCb/Tc7TzcvR6hQcLuIyd4bdZmFm3fz50dziU4SEhK8fP6z1sAuLB2RbrVr0yK30+Sz88L328KcPWnHTt+kvnLNvH8A9emjpsyawUffrUAgEs6NuXay87PbPYi45fV25g0bQmN6lSlQ98XAHji7l50b984wJUVfVIY/TgiUh3nZxsNgShgkqre4R4B/QinBfcrUB54yj0oMAGn7+sP4DAwRVUnpPvZxn+BOFXdJyIf4/S3TXf70RCRGThHV9/OrsYWLVvpj3MX5+t2F5Zr3imedQNMuqXoB0xmypUMDXQJ/7MiQmW528d+hkLp/FDVP4BeACLSDvhERFqq6gqgXybz3JTJ+E5phmPTDPdNO52IlMT5icgnZ1e9Maa4KPSDAqq6UFVrumFWIESkG06L701VPVxQ6zHGFC1F5/BUPlLVH4Gaga7DGFO4ivLPNowxJlcs0IwxnmGBZozxDAs0Y4xnWKAZYzzDAs0Y4xkWaMYYz7BAM8Z4hgWaMcYzLNCMMZ5hgWaM8QwLNGOMZ1igGWM8wwLNGOMZFmjGGM/w5PXQ8kIQgoOKxjX+c2vqoLaBLiHPFm3bH+gS8qxD3ahAl2DSsRaaMcYzMm2hicibQKZ3UFHVoQVSkTHG5FFWu5zLCq0KY4zJB5kGmqqecctjESmpqscKviRjjMmbbPvQRKStiGwANrqPm4vI6AKvzBhjciknBwVGApcA+wFUdTXQsSCLMsaYvMjRUU73RsFp+QqgFmOMOSs5+R3aH+7dzlVEQoF7cG7ia4wxRUpOWmh3AncD5wC7gBbuY2OMKVKybaGp6j6gXyHUYowxZyUnRznPFZFvRSReRPaKyDcicm5hFGeMMbmRk13Oj4HPgBigKvA58ElBFmWMMXmRk0ArqaofqmqK++8jILygCzPGmNzK6lzOCu7gdBF5BPgU59zO64BphVCbMcbkSlYHBZbjBNipa+rckeY5BYYVVFHGGJMXWZ3LWaswCzHGmLOVows8ikgToBFp+s5U9YOCKsoYY/Ii20ATkeFAJ5xAmwb0AOYDFmjGmCIlJ0c5rwG6An+p6s1Ac6BcgVZljDF5kJNdzuOq6heRFBEpC+wFqhdwXcWez+fn0lv/j5iocnzwyh3MX/4bI0Z9Q3JyCs3qV+fVYTcQEhIc6DLP8Oeeg9z99IfEHziKiND/ynbccV2n1OdHT/yJ4W9+zcYZz1MxsnTgCnUlJaUwbMR4klN8+Hx+2rdpSN9rOjP1+yVMmfELf+05yEdvP0TZsiUBUFXGfTCDZas2UyIslHvvvJLatWICvBUZ+3HhBoa9+gU+v5/+vdtx303dA11Sjuz86yCDnvrA+QwBA/u0584bOhfa+nMSaMtEJBIYh3PkMwFYlN1MIpKgqmf1qReROGBAZpf7FpFYoJ2qfpyT6QvTO5/PoW5sNAmJJ/D7/dzz7EQ+e/1uateozMvjpvHZ9CX0vaJo3dwkODiIp4f2oXmD6iQknqDrTa/Q6fz61K8Vw597DvLzko1Uq1I+0GWmCg0N5tnHBxIRHkZKio9Hnh5Py+Z1aVi/Oq1b1uOxZyacMf3yVVvY9dcB/vPaEDZt+ZMx733H/z3zz8AUnwWfz89DL3/GV6MGUzU6ki4DX6FHx6Y0OLdohm9aISFBPHvvVTRvUJ2jiSfoPOAlOrVpUGi1Z7vLqap3qeohVX0buBgY6O56FjhVXZZNOMUCfXMxfaHYtfcQsxauTw2sg4ePERYSTO0alQG4qHV9ps1eHcgSM1SlUjmaN3Aa36VLhVMvNprdew8D8PjIyQwf3Buh6NwZS0SICA8DnBBI8fkQgdqxMURHRf5t+sXLN9K5QzNEhAZ1q5F47AQHDh4t7LKztXz9fzm3eiViq1UiLDSEqy5uybQ5awJdVo6k/QyVKRVOvdgq7I4/VGjrzzTQRKRl+n9ABSDEHc41EWkhIr+IyBoR+UpEyrvjW7vjVonIKyKyzh3fSUSmusMXuc+vEpGVIlIGeBHo4I67L930pUVkvIisdZd9dV5qzovhr0/m8bt6EyTOH3+FyFKk+Pys/nUHAFNnr2LX3sJ7k/Nix679rP3tT1o1qcn0uWuIiYqkSd1zAl3W3/j8fu4Z9jb973yFFk3PpX6daplOu//gUaIqnO7+rVihLPuLYKDtjj/MOdGnW8JVo8uzO/5wACvKmx279rNm005aNY4ttHVmtcv5ahbPKdAlD+v7ABiiqnNEZAQwHLgXGA/cpqqLROTFTOZ9ELhbVReISGngBPAI8KCq9gQnANNM/wRwWFWbus/9bV9JRG4HbgeoVr1GHjbn735YsI5K5UvTrEF1Fq7YfGo9jBkxkOFvfEVScgoXnd+AoKCiewfBhGMnuXnYuzx771UEBwczcsIPfP7GXYEuK0PBQUG8/sKdJCSe4IV/T+L3P/ZSs3rlQJf1Py/h2EkG/OsdXrj/asqWjii09Wb1w9p87ckTkXJApKrOcUe9D3zu9s+VUdVT/XIfAz0zWMQC4DURmQhMVtWdIlnu/nQDrj/1QFUPpp9AVccCYwHOaxmX6S37cmPpmu3MnL+OWYt+5WRSMkcTTzD46Q8YNXwAX4+5B4DZizey7Y+9+bG6fJec4uPmYe9yzSVx9OzcnA1bdrFj93463fgSALviD9F14Ct8/94DRFcsG+BqTytdKpymjWJZsXpLpoFWsXwZ4g+cbunsP3CEiuXLFFaJORYTVY4/95z+uO7ac5CYqOLzw4LkFB8D/zWOay+N44ouLQp13UW3mZCOqr4I/BOIABaISIMAl5ShRwddwfKvR7Dky+GMeXogF7aqy6jhA9jn7tqcTEph9MQf6X9l+wBX+neqyr3PfUy92GgG9XUa4I3qVOXX6c+z4uunWPH1U1SNimTW+w8ViTA7fCSRhMQTAJxMSmbV2m1Uq1op0+nPb1Wfn+etQVXZuHknJSNKUKEIBlrLRjXZuiOe3//cR1JyCpN/WEGPjs0CXVaOqCpDnplIvdgq3N2va6GvP0dnCuQHVT0sIgdFpIOqzgP6A3NU9ZCIHBWRNqq6mDStqrREpLaqrgXWikhroAHwB5DZJ/IHnCvr3uvOXz6jVlphGT3xJ35cuB6/XxnYpz0XtqoXqFIytXj1Nj6bvpRGtavSqb/TIntsUE8ubtc4wJVl7MChBEaO+Rq/34+qcuEFjWndsh7fzljM5KkLOHgogaGPjKFVi7oMub0XcS3qsnzVZu64701KlAhl6B29A70JGQoJCeblh//B1UPfwudT+vW6gIa1i/4RToBfVm9j0rQlNKpTlQ59XwDgibt70b194XyGRDVf9rT+vmARP84lu095DfgJeBsoCWwDblbVgyLSBudnIX5gDhCnqu3dPrEHVbWneyf3zu4064Gb3OHvgYrABGBlmulLA28BrXBu6vK0qk7OrN7zWsbpT/MX59PWF67Q4KJz5DG3Fm3bH+gS8qxD3ahAl/A/KyJUlqtqXPrxOTn1SXAuwX2uqo4QkRpAFVVdktV8qprZ7uwFGYxbr6rN3PU9gnvXdlWdDcx2h4dksrz0BydOTZ8ADMyqRmOMt+SkD2000Ba4wX18FKflk58ud396sQ7oADybz8s3xvwPyEkfWhtVbSkiK8E5WigiYflZhKpOAibl5zKNMf97ctJCSxaRYJzfniEiUTh9V8YYU6TkJNDeAL4CKovIcziXDnq+QKsyxpg8yMl9OSeKyHKcSwgJcKWq2p3TjTFFTk6OctYAjgHfph2nqjsKsjBjjMmtnBwU+I7TN0sJB2oBm4Ci+WtLY8z/rJzscjZN+9i90kbRPFPZGPM/LdfncqrqCqBNAdRijDFnJSd9aPeneRgEtOTMU5qMMaZIyEkfWtqTv1Nw+tS+LJhyjDEm77IMNPcHtWVU9cFCqscYY/Isq0twh6iqDyh6F+4yxpgMZNVCW4LTX7ZKRKYAnwOJp57M6lI8xhgTCDnpQwsH9uNcpufU79EUsEAzxhQpWQVaZfcI5zpOB9kpBXNVSGOMOQtZBVowUBoyvBGjBZoxpsjJKtB2q+qIQqvEGGPOUlaBVnwvVJ8HIhAeWmxugnWGFF/xbTAX5+vyz/z1r0CXcFa6N6wS6BLyXVZ/wYV/DypjjDkLmQaaqh4ozEKMMeZsFc99LGOMyYAFmjHGMyzQjDGeYYFmjPEMCzRjjGdYoBljPMMCzRjjGRZoxhjPsEAzxniGBZoxxjMs0IwxnmGBZozxDAs0Y4xnWKAZYzzDAs0Y4xkWaMYYz8jJbezMWRj98U98+M0iRIRGdWIY9cSNhJcIDXRZGfpzz0EGj/iQ+ANHERH6927H7dd1AuCdz+fw3hfzCA4Oolu7xgwf3DuwxebAjws3MOzVL/D5/fTv3Y77buoe6JJSJSWl8NTzH5CcnILf76dN64b846qLePudb9m6fTcAMVUqcNdtvQgPD+P9iTNZ/+vvzrwnkzl8NJHxbz8UyE3IVCBf9yIfaCLyGNAX8AF+4A5VXZzJtBOAqar6ReFVmLldew8xdtIcFk16jIjwMG4e9h6Tf1hO354XBLq0DIUEB/H00D40q1+dhMQTdLv5FS46vz7xB44yfe5afv7wX5QICyX+wNFAl5otn8/PQy9/xlejBlM1OpIuA1+hR8emNDg3JtClARAaGsyTj9xIeHgYKSk+hj/7Pi2a1WZAv+6UjCgBwAcTf2DGD0u58or2DOx3OhSmz1zKf38vmvczCPTrXqR3OUWkLdATaKmqzYBuwB+BrSp3Unx+TpxMJiXFx/ETSVSpVC7QJWUqulI5mtWvDkDpUuHUi41md/xhJkyez9D+F1MizGlZRlUoE8gyc2T5+v9ybvVKxFarRFhoCFdd3JJpc9YEuqxUIkJ4eBjghECKz4+IpIaZqpKUnIzI3+9VtPCX9bRv27hQ682pQL/uRTrQgBhgn6qeBFDVfaq6S0SeFJGlIrJORMZKBu+6iLQSkTkislxEvheRQv9qrlo5ksE3dqVZrydpeNnjlC0dQZcLGhZ2GXmyY/d+1v72J60a12TrH/H8snorl976Kr0Hvc7KDb8Hurxs7Y4/zDnR5VMfV40uz+74wwGs6O/8fj8PPz6O2wa/RrMmtahb+xwARo+bwh1DRvLn7v1cenHrM+aJ33eIvfGHaNIoNgAVZy/Qr3tRD7SZQHUR+U1ERovIRe74UaraWlWbABE4rbhUIhIKvAlco6qtgPeA59IvXERuF5FlIrJs3774fC/+0JFjTJ+zhpVfP8WGac9y7PhJPpu+NN/Xk98Sjp3klmHv8sy9V1GmVAQ+n9/ZlnfuZ/jgK7nt8fGoFt9b5xUVQUFBvPzsbYwZeQ9btu1ix869ANx1Wy/efuMezompxMLF68+YZ+EvG2jTugFBQUX9TzcwivSroqoJQCvgdiAemCQiNwGdRWSxiKwFugDp29/1gSbADyKyCngcqJbB8seqapyqxlWqlP/3h5y9ZBM1qlakUvkyhIYE07Nzc5as2Zbv68lPySk+bnn0Xa6+JI6enZoDEBNVjss7NUNEaNm4JhIk7D+UEOBKsxYTVY4/9xxMfbxrz0Fioorm7n6pUuE0bliT1Wu2po4LCgqi3QWNWLJ04xnTFuXdTQj8616kAw1AVX2qOltVhwODgX7AaJzWV1NgHBCebjYB1qtqC/dfU1Ut9ENc1aqUZ9m6/3LsRBKqytylv1Evtuje3FVVufe5j6lXM5pBN3RJHd+jYzPmL98MwNYde0lO9lExsnSgysyRlhH34V4AABLOSURBVI1qsnVHPL//uY+k5BQm/7CCHh2bBbqsVEeOJJKYeAKApKRk1q7bTtWYivy1x7l7pKqyfOVmqlatlDrPn7v2kXjsBPXq/O27ucgI9OtepI9yikh9wK+qm91RLYBNQDNgn4iUBq4B0h/V3AREiUhbVV3k7oLWU9X1FKK4JrH06tqCzv1fIjg4mGb1qzGwT7vCLCFXFq/ZxuczltKwdlU6D3gJgMfu7EnfKy7gnuc+pmO/FwgNCebNJ27MsLO6KAkJCeblh//B1UPfwudT+vW6gIa1i8YRToCDhxIYPXYKflX8fqVtm4ac17wuw597n+PHT6IKNWtU5p83XZY6z8Jf1tOuTeMi/doH+nWXotwXIiKtcPrCIoEUYAvO7ue9wA3AX8BvwO+q+lTan22ISAvgDaAcTnCPVNVxma2rZas4XfBL0e/fykiKr+i+h9kJDSnyOwmZmvlr0fzpRE51b1h09xayExEqy1U1Lv34It1CU9XlQEZNmsfdf+mnvynN8CqgY4EVZ4wpcorv16MxxqRjgWaM8QwLNGOMZ1igGWM8wwLNGOMZFmjGGM+wQDPGeIYFmjHGMyzQjDGeYYFmjPEMCzRjjGdYoBljPMMCzRjjGRZoxhjPsEAzxniGBZoxxjMs0IwxnmGBZozxjCJ9CW6TMyHBRfemGdlJPJkS6BLyrDhfkx/gp417A11CvrMWmjHGMyzQjDGeYYFmjPEMCzRjjGdYoBljPMMCzRjjGRZoxhjPsEAzxniGBZoxxjMs0IwxnmGBZozxDAs0Y4xnWKAZYzzDAs0Y4xkWaMYYz7BAM8Z4hgWaMcYzLNCMMZ5hl+AuYM17D6d0yRIEBwUREhzETx88HOiScqW41X/BNU9TqmQ4wUFCSHAw0959gPWbd/LIK59zMimZkOBgnnvgGs5rVDPQpWbqxMlkLr99JCeTU/Cl+OjV9TyG3XF5oMtKlZSUwhPPTSA52YfP76dt64Zcf3UnRo6ezNbtuwkODqJu7XO44+bLCQkJ5uvvFjJv4VoAfD4/f+7ax3ujH6RM6Yh8r63AA01EHgP6Aj7AD9yhqovPcpkjgLmq+mM+lFjgpowZSsXI0oEuI8+KW/2fv3E3FdLU+9zob7nv5kvo0rYRsxZt4LnRU/hi1JAAVpi1EmEhfDNmKKVLliA5xUePf75Gt3aNaN20VqBLAyA0NJinhg0gIjyMlBQfjz8znpbN69ChXVPuGdQHgH+PnsyPs1dyabc4rry8HVde3g6ApSs2MXXG4gIJMyjgQBORtkBPoKWqnhSRSkBYDucNUdUM76Chqk/mY5nG40Qg4dgJAI4mHCe6UrkAV5Q1EaF0yRIAJKf4SE7xIVJ0boQjIkSEO3/GPp+fFJ8fgFYt6qZOU/fcc9h/8Mjf5p3/y3oubNukwGor6BZaDLBPVU8CqOo+ABFpBbwGlAb2ATep6m4RmQ2sAi4EvhWRW4BaquoXkVLARuBcYBwwVVW/EJHWwOtAKeAk0BU4BrwIdAJKAG+p6n8KeFszJMDVQ95CRBjYpz039WkfiDLyrLjVLyL0vf9tBOjXux039m7HU0P70O/+t3nmrSn4/co3b98T6DKz5fP56dT/JbbvjOfWazsS1yQ20CWdwef38/AT4/hrzwEu7daaenWqpT6XkuJjzoI13NL/kjPmOXkymVVrtvDPAT0KrK6CDrSZwJMi8hvwIzAJWAi8CfRW1XgRuQ54DrjFnSdMVeMARKQlcBHwM05L73tVTT71bSUiYe4yr1PVpSJSFjgO3AocVtXWIlICWCAiM1V1e9riROR24HaA6jVqFMgLMG3cfVStHEn8gaNcNXgU9WpG065lnQJZV0EobvVPHj2UmKhI9h08yg33jqFOzWi+m72K4UP7cHmn5nw7ayUPvvApn75+V6BLzVJwcBDzPh7G4aPHuPGhcWzYsotGdaoGuqxUwUFBvPrcHSQmnuCl1yex44+91KheGYBx70+jUYOaNKp/Zj/lspW/Ub9u9QLb3YQCPsqpqglAK5zQiMcJnzuAJsAPIrIKeByolma2SemGr3OHr0/3HEB9YLeqLnXXd8TdTe0ODHCXvxioCNRNNy+qOlZV41Q1rlKlqLPa1sxUrRwJQFSFMlzeqTnLN/xeIOspKMWt/pgop95K5ctwacemrNrwO19MX8plFzUDoGeXFqz6tWhvQ1rlypSkQ6t6zFq0IdClZKhUqXCaNIxl5ZotAHw2eQ6Hjxzjpr7d/zbt/F/W0aEAdzehEH62oao+VZ2tqsOBwcDVwHpVbeH+a6qqabc+Mc3wFOBSEamAE4w/5XC1AgxJs45aqjozP7YnNxKPn+Ro4onU4Z8Xb6Rh7ZjCLiPPilv9x46fTO0rO3b8JHOXbqL+uTFEVyrLopXOH9yC5ZupVa1gvrzyy76DRzl89BgAx08k8fOSjdSNjQ5wVacdPpJIovu5OJmUzJp12zinaiV+nL2CVWu3ct/dVxEUdGafX+KxE2zY+DutW9Yv0NoK+qBAfcCvqpvdUS2AX4HuItJWVReJSChQT1XXp59fVRNEZClOH9lUVfWlm2QTECMird1dzjI4u5zfA4NE5Cd3F7Ue8KeqJlKI4g8cpf9D4wBI8fm55pI4urVtVJglnJXiVn/8gaP889H3AKcP6sqLW9L5goaUiijB8Ncnk+LzUyIshJcevi6bJQXWX/uOcNdTH+Lz+/H7lT7dWnJph6aBLivVwUMJjBr7DT6/H/Ur7do0Iu68elw78BmiKkXy6NPOe9AmrgH/6HMRAIuXbaR5k9qEh+fomGCeiaoW3MKdzv83gUggBdiCs/tZDXgDKIcTqiNVdZx7UOBBVV2WZhnXAJ8DnVR1jjtuAmceFHgTiMAJs244BwWeBa7Aaa3FA1eq6uHMam3ZKk4X/LI0/zbe5MixpPTfUcVHqRLF+2ecP23cG+gS8uzyptHLT/W1p1WggVacWKAFhgVa4Hgx0OzUJ2OMZ1igGWM8wwLNGOMZFmjGGM+wQDPGeIYFmjHGMyzQjDGeYYFmjPEMCzRjjGdYoBljPMMCzRjjGRZoxhjPsEAzxniGBZoxxjMs0IwxnmGBZozxDAs0Y4xnWKAZYzzDLsHtEpF4oCDvb1YJ56bKxZHVHhhWe+Zqqurfbt9lgVZIRGRZRtdALw6s9sCw2nPPdjmNMZ5hgWaM8QwLtMIzNtAFnAWrPTCs9lyyPjRjjGdYC80Y4xkWaMYYz7BAy4aI+ERklYisE5HPRaTkWSxrtojk+lC2iESKyF1nsd5qIvKNiGwWkW0iMkpESuRxWanbICLT3NrOqr5M1pOQD8uIE5E3sng+VkT65nT6/CQij4nIehFZ436+2mQx7QQRuaYw6sptbblY5ggR6ZYf9WXFAi17x1W1hao2AZKAO9M+KSIhhVBDJJCnwBARASYDX6tqXaAuEAG8fLZFqeplqnrobOorSKq6TFWHZjFJLJAaaDmYPl+ISFugJ9BSVZsB3YA/Cnq9OXE2tWX1t6CqT6rqj/lTZeYs0HJnHlBHRDqJyDwRmQJsEJFwERkvImtFZKWIdAYQkQgR+VREfhWRr3CCBPe5hDTD14jIBHc4WkS+EpHV7r92wItAbffb8pVc1twFOKGq4wFU1QfcBwwQkcEiMipNHVNFpJM7PEZElrnf1E9ntGAR+a+IVEpfn4h8ICJXppluooj0zmXdGa2vhYj84rYcvhKR8u741mlaE6+IyDp3fCcRmeoOX+Q+v8p9j8q4dXdwx92XbvrSad7TNSJy9dnWn0YMsE9VTwKo6j5V3SUiT4rIUndvYKz7ZZT+NWglInNEZLmIfC8iMflYV1a1Zbhet8U+UkSWAY+JyO8iEuQ+V0pE/hCR0LStTPf9Wuh+vpeISBkRCXbfu6Xu631HnqpXVfuXxT8gwf0/BPgGGAR0AhKBWu5zDwDvucMNgB1AOHB/mvHNgBQgLu1y3eFrgAnu8CTgXnc4GCiH05JYl8f6hwL/zmD8SuBeYFSacVOBTu5whTQ1zAaauY9np9mG/+Kc4nJGfcBFOC1C3Pq3AyF5ed3TjVsDXOQOjwBGusPrgLbu8IunanHfp6nu8LdAe3e4tPt+pj6fwfQvnVq++7h8Pn6mSgOrgN+A0Wm2qUKaaT4ErnCHJ7ifkVBgIRDljr/u1OerIGvLar3u52F0mvm/ATqnme6ddNsQBmwDWrvjy7rvxe3A4+64EsAy3L+v3PyzFlr2IkRkFc4LvAN41x2/RFW3u8MXAh8BqOpGnHNC6wEd04xfg/MHmZ0uwBh3Hp+qHs6n7citf4jICpzgaww0yumMqjoHqCsiUcANwJeqmnI2xYhIOSDSXTbA+0BHEYkEyqjqInf8x5ksYgHwmogMdZeTXT3dgLdOPVDVg3mv/kyqmgC0wvkjjgcmichNQGcRWSwia3E+B43TzVofaAL84H4mHweq5VddmdUG3JHNeielG77OHb4+3XOntmG3qi5113fEfS+64+w1rAIWAxVxukdypTD6f4q746raIu0Id08g8SyXm/YHgOFnuaysbMD5ZkwlImWBKsB+nOA9ow4RqQU8iPMtetDdHc5tjR8AN+J8qG/OU+X5SFVfFJHvgMuABSJySYDr8eG0bma7AXYHTis+TlX/EJGn+PtrLsB6VW1byLXdnc160/4tTAGeF5EKOMH4Uw5XK8AQVf0+b1U7rIWWP+YB/QBEpB5QA9gEzMXtdBaRJjgf2FP2iEhDt7+hT5rxs3B2a3H7FcoBR4EyeaxtFlBSRAacWibwKjAKZ1ewhYgEiUh14Hx3nrI4H9LDIhIN9MhmHRnVNwFnlxZV3ZDH2lO5LdWDItLBHdUfmKPOQYmjcvpI3PUZzS8itVV1raq+BCzF6RrI6nX9AecP+dT85c92G9Isq76IpG19tMD5vADsE5HSpPsScm0CosTpuMftm0rfiiuI2n7N6XrdFt5S4HWc3XdfBtsQIyKt3WWVEedgwvfAIBEJdcfXE5FSua3fWmj5YzQwxv02SwFuUtWTIjIGGC8iv+J8KJanmecRnD6reJzd2dLu+HuAsSJyK+ADBqnqIhFZ4HZ2T1fVh3JamKqqiPQB3hKRJ4AoYJKqPud2Om/HacX9Cqxw51ktIiuBjThHuBZks4796etT1T3udn+d01rTKSkiO9M8fg0YCLwtzk9ntnG65XcrME5E/MAcIKPd9HvFOVjjB9YD091hn4isxgnglWmmfxbnNVuH8z48jXO0OD+UBt50d5dTgC04u3iHcPoD/8IJhTOoapLbsf6G+0UXAox0tye/ZFbb2FysdxLwOU6fZEbbcJ27jgjgOM7u/Ts4fbEr3M9lPHBl+vmzY6c+/Y8R56jpJ0AfVV1RgOspCazFOfxfoP2AIlLabRkgIo8AMap6T0Gu0xRN1kL7H6OqC4GaBbkOcX5A+S7O0dXCOKhxuYgMw/k8/w7cVAjrNEWQtdCMMZ5hBwWMMZ5hgWaM8QwLNGOMZ1igmXwl+Xt1krTn/70jIpmerSDOeZjt8rCOU+ej5mh8umlydUUQEXlKRB7MbY0m5yzQTH4rkKuTqOo/s/mBbicg14FmvMUCzRSkzK5OkuGVFcQxSkQ2iciPQOVTC5Izr8N2qYisEOdqDbNEJBYnOO9zW4cdRCRKRL5017FURNq781YUkZniXEXkHZxTbrIkIl+Lc5WJ9SJye7rn/u2OnyXOuauISG0RmeHOM09EGuTHi2myZ79DMwXCbYn1AGa4o1oCTVR1uxsKh1W1tTgXmlwgIjOB83BOXm4EROOcwfBeuuVGAeOAju6yKqjqARF5G+cKHf/nTvcxzu/g5otIDZxTaxoCw4H5qjpCRC7HOcsgO7e464gAlorIl6q6HygFLFPV+0TkSXfZg3F+VX+nqm4W55Ss0Tgnm5sCZoFm8tupq5OA00J7F2dXMO3VSboDzeT0VVjL4VxZoSPwiXv+3y4RyejE5guAuaeWpaoHMqmjG9BITl9SrKw450h2BK5y5/1ORHJyFY2h7uljANXdWvfjnDp16moSHwGT3XW0Az5Ps+48XR3Y5J4FmslvObk6SYZXVhCRy/KxjiDgAlU9kUEtOSbOBS+74Vxv7ZiIzCbzK4+ou95D6V8DUzisD80EQmZXVpgLXOf2scUAnTOY9xec66DVcuet4I5Pf+WMmcCQUw9E5FTApL0CSg8gu6tolAMOumHWAKeFeEoQp6+K0RdnV/YIsF1ErnXXISLSPJt1mHxigWYC4R2c/rEV7tUs/oOzt/AVsNl97gNgUfoZVTUe5+oPk92rZJza5fsW6HPqoADOlXrj3IMOGzh9tPVpnEBcj7PruSObWmcAIeJcOeRFnEA9JRE4392GLjhX0QXnUlK3uvWtB8768uMmZ+xcTmOMZ1gLzRjjGRZoxhjPsEAzxniGBZoxxjMs0IwxnmGBZozxDAs0Y4xn/D/50Zbr4qBvQAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#reviewType_Validate_phobert_model.\n","\n","model = torch.load(model_path)\n","_, predictions, true_vals = evaluate(model,dataloader_test)\n","accuracy_per_class_df = accuracy_per_class(predictions, true_vals, model_type, epochs, train_data_provider)\n","accuracy_per_class_df_path = path_data_final+'reviewtype__accuracy_per_class_df.csv'  \n","accuracy_per_class_df.to_csv(accuracy_per_class_df_path, index=False)\n","true_vals= true_vals.reshape(-1)\n","confusion_chart=confusion_matrix_function (true_vals,predictions)\n","print(confusion_chart)\n","best_epoch_F1_score_macro = eval_df[eval_df['F1_score_macro'] == max(eval_df['F1_score_macro'])]['epoch'].values[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":477,"status":"ok","timestamp":1660754795731,"user":{"displayName":"suwasit wittawijugbbt","userId":"09267968935034910060"},"user_tz":-420},"id":"1sh3BVdJiOp5","outputId":"07af10a2-2ae8-47df-8484-aacc24b68eb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predict review type :  Quality\n"]}],"source":["#reviewType_text_test_prediction.\n","\n","def predict_text(input_text):\n","  inputs = tokenizer(input_text.lower(), return_tensors = \"pt\").to(device)\n","  with torch.no_grad():\n","      logits = model(**inputs).logits\n","\n","  predicted_class_id = logits.argmax().item()\n","  return label_dict_inverse[predicted_class_id]\n","\n","\n","model.eval()\n","input_text='Sản phẩm rất tốt, và mạnh mẽ'\n","print(\"Predict review type : \",predict_text(input_text ))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":565},"executionInfo":{"elapsed":2293,"status":"ok","timestamp":1660755119258,"user":{"displayName":"suwasit wittawijugbbt","userId":"09267968935034910060"},"user_tz":-420},"id":"Sr-Sf0eBiyHW","outputId":"5ad089fe-75f8-4999-9c84-46028e563da9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model comparison chart is saved ,please check\n"]},{"data":{"text/html":["\n","<div id=\"altair-viz-db453418cf1c448591cf0f484e4a2a41\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-db453418cf1c448591cf0f484e4a2a41\") {\n","      outputDiv = document.getElementById(\"altair-viz-db453418cf1c448591cf0f484e4a2a41\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300, \"stroke\": null}, \"concat\": {\"spacing\": 6}, \"title\": {\"fontSize\": 10.5}}, \"hconcat\": [{\"data\": {\"name\": \"data-85b1dfe1f0986919f3f58a251fb75ac8\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"field\": \"line type\", \"legend\": {\"direction\": \"horizontal\", \"labelColor\": \"black\", \"labelFontSize\": 15, \"orient\": \"bottom\", \"titleColor\": \"black\", \"titleFontSize\": 11}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"line type\", \"type\": \"nominal\"}, {\"field\": \"value\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0, 1.2]}, \"title\": \"\", \"type\": \"quantitative\"}}, \"height\": 300, \"selection\": {\"selector006\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": {\"text\": [\"Model1\", \"Phubert_1\", \"Full data\", \"dropout 0.1\", \"\"], \"subtitle\": [\"\", \"\"], \"color\": \"black\", \"subtitleColor\": \"black\", \"anchor\": \"middle\", \"fontSize\": 15, \"subtitleFontSize\": 10, \"offset\": 1}, \"width\": 300}, {\"data\": {\"name\": \"data-358903c642f267f0d3973bb5921e2aa0\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"field\": \"line type\", \"legend\": {\"direction\": \"horizontal\", \"labelColor\": \"black\", \"labelFontSize\": 15, \"orient\": \"bottom\", \"titleColor\": \"black\", \"titleFontSize\": 11}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"line type\", \"type\": \"nominal\"}, {\"field\": \"value\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0, 1.2]}, \"title\": \"\", \"type\": \"quantitative\"}}, \"height\": 300, \"selection\": {\"selector007\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": {\"text\": [\"Model2\", \"Phubert_1\", \"Group_class\", \"droup 0.1\", \"\"], \"subtitle\": [\"\", \"\"], \"color\": \"black\", \"subtitleColor\": \"black\", \"anchor\": \"middle\", \"fontSize\": 15, \"subtitleFontSize\": 10, \"offset\": 1}, \"width\": 300}, {\"data\": {\"name\": \"data-a98b6d030136ba8870dba72bbbd3f012\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"field\": \"line type\", \"legend\": {\"direction\": \"horizontal\", \"labelColor\": \"black\", \"labelFontSize\": 15, \"orient\": \"bottom\", \"titleColor\": \"black\", \"titleFontSize\": 11}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"line type\", \"type\": \"nominal\"}, {\"field\": \"value\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0, 1.2]}, \"title\": \"\", \"type\": \"quantitative\"}}, \"height\": 300, \"selection\": {\"selector008\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": {\"text\": [\"Model3\", \"Phubert_1\", \"Remove_class\", \"dropout 0.1\", \"\"], \"subtitle\": [\"\", \"\"], \"color\": \"black\", \"subtitleColor\": \"black\", \"anchor\": \"middle\", \"fontSize\": 15, \"subtitleFontSize\": 10, \"offset\": 1}, \"width\": 300}, {\"data\": {\"name\": \"data-024fc1542d6345d2c5b53edce4f727e8\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"field\": \"line type\", \"legend\": {\"direction\": \"horizontal\", \"labelColor\": \"black\", \"labelFontSize\": 15, \"orient\": \"bottom\", \"titleColor\": \"black\", \"titleFontSize\": 11}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"line type\", \"type\": \"nominal\"}, {\"field\": \"value\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0, 1.2]}, \"title\": \"\", \"type\": \"quantitative\"}}, \"height\": 300, \"selection\": {\"selector009\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": {\"text\": [\"Model4\", \"Phubert_1\", \"Remove_class\", \"dropout 0.4\", \"\"], \"subtitle\": [\"\", \"\"], \"color\": \"black\", \"subtitleColor\": \"black\", \"anchor\": \"middle\", \"fontSize\": 15, \"subtitleFontSize\": 10, \"offset\": 1}, \"width\": 300}, {\"data\": {\"name\": \"data-f2247bd58ebdb2b9ff789266d08eff87\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"field\": \"line type\", \"legend\": {\"direction\": \"horizontal\", \"labelColor\": \"black\", \"labelFontSize\": 15, \"orient\": \"bottom\", \"titleColor\": \"black\", \"titleFontSize\": 11}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"line type\", \"type\": \"nominal\"}, {\"field\": \"value\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0, 1.2]}, \"title\": \"\", \"type\": \"quantitative\"}}, \"height\": 300, \"selection\": {\"selector010\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": {\"text\": [\"Model5\", \"Phubert_1\", \"upsample_minority_class\", \"dropout 0.4\", \"\"], \"subtitle\": [\"\", \"\"], \"color\": \"black\", \"subtitleColor\": \"black\", \"anchor\": \"middle\", \"fontSize\": 15, \"subtitleFontSize\": 10, \"offset\": 1}, \"width\": 300}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-85b1dfe1f0986919f3f58a251fb75ac8\": [{\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.4939268086197662}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.4415756697784706}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.3923651400402507}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.3748215518596397}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.3494733155133868}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.3252460146946286}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.3084217692066193}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.2777406574432171}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.2517268972738236}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.2313016533502017}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.2106396995655555}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.1901969887175293}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.1876430215740727}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.1616623631812081}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.1514570912589085}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.1348900348635056}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.1201288538716425}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.1093970427147413}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.094714103069449}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"train_loss\", \"value\": 0.1089439529722037}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.4207798095282029}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.5295686083749979}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.4949043532632245}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.5180220434331017}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.4688821438098242}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.5733086644162121}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.5417383462875706}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.582292224806561}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.5487188137406598}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.6524517149015314}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.8144185543193246}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.8165414450968493}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.8505406307538975}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.84480283370013}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.8977589405585155}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.8854887797905026}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 0.9584242528512376}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 1.0804169702508863}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 1.006152536084005}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"val_loss\", \"value\": 1.0107013647351846}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.856172575261166}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8254657604221484}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8639791692589075}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.860060462118884}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8796728786039673}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.870998925151459}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8775906260931958}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8661941106019602}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8609335134200733}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8754084820296685}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8520358721429612}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8545366345994838}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8610618508421809}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.863096681225963}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.860036539619668}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8769379437297451}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8680958895743915}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8604461503027679}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.8678828857585003}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_weighted\", \"value\": 0.857076782266756}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.506520480870633}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.4869575744605944}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.5415899009288586}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6008767467538374}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6418364668826266}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6291192160197288}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6305874854669222}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6393303845077437}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6683677209964577}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6274378636770281}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6570504297451776}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.653619431253766}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6900449461406014}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.654359245216716}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6671811568741808}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6924647612182361}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6831675495992174}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6823502225204499}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.6959940669886835}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_macro\", \"value\": 0.664200406545017}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8629572385368367}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8341061308603812}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8701700154559505}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8660484286450283}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8830499742400825}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8742916022668727}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8799587841318908}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8696548171045853}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8639876352395673}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8773827923750644}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8557444616177228}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8552292632663575}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.863472436888202}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8650180319422978}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8583204533745492}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8763523956723338}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8686244204018547}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8608964451313755}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8660484286450283}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 1, \"line type\": \"F1_score_micro\", \"value\": 0.8557444616177228}], \"data-358903c642f267f0d3973bb5921e2aa0\": [{\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.4897799879431448}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.4450545720986247}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.4139426892875558}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.3704891137066119}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.3506548920596914}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.3430827281000927}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.3157754378778386}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.2945264315698536}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.2727845810183749}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.2606525276073621}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.2341116259081829}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.2167462856200908}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.1982190188052359}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.1737082348766004}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.1613789581076024}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.1513822488513293}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.1328482648020282}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.1295964199007535}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.1054897855819186}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"train_loss\", \"value\": 0.1041735808236117}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.5240331142220969}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.4840761530155569}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.4128440078060476}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.5140892642525259}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.5026236530182568}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.5637758736189171}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.5456905875013903}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.6720041058645698}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.6884286880927686}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.7071811287130187}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.7453070571339486}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.7743573061211145}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.8577842980665404}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.8468567441329465}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.955279928558782}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.9101204125790564}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.8895430931393412}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 0.9536974108939628}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 1.0253979210635702}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"val_loss\", \"value\": 1.2069919061804932}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8419776597960943}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8584465580285243}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8665120991137631}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.873994907612959}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8759694399323336}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8687874373024288}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8752054807153075}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8603326560240119}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8680608385424168}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8492211549553512}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.872316212895811}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8555738126422971}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8708430081434154}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8689705407780923}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8609867230245108}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8609045603910255}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8682785257612939}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8671670690073339}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8627799702379841}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_weighted\", \"value\": 0.8495921060109307}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.625644461860198}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.6390192103119348}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.643879368407062}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.6498532317940054}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7215136211089892}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7390453744142007}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7196196750460316}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7446859693633586}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.698232751232793}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7368809139563198}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7622393306021795}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7413240477752397}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7612292304603177}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7790867988181077}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7608487599016074}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7664273707163396}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7816307741608891}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7680888483102699}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7617009381071895}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_macro\", \"value\": 0.7115884509928674}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8464708912931479}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8645028335909326}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8737764039155074}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8815043791859866}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8794435857805255}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8717156105100463}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8794435857805255}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8619268418341062}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.872746007212777}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8536836682122617}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8706852138073158}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8583204533745492}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8665636269963937}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.86913961875322}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8588356517259145}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8619268418341062}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8675940236991242}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8675940236991242}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8603812467800102}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 2, \"line type\": \"F1_score_micro\", \"value\": 0.8397733127253992}], \"data-a98b6d030136ba8870dba72bbbd3f012\": [{\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.3724358730554236}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.334240010127566}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.3121189926902591}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.2971990565206129}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.2766586085730707}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.2711135984834126}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.2432642601159677}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.2222401382726374}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.2012121887698925}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.1946120776352289}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.1560329445118357}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.1598609448010393}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.1445334026007729}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.1163301061932688}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.1123776441054972}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.0960552278296623}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.0855454505720085}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.0697696332672345}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.0864243192475617}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"train_loss\", \"value\": 0.070855131820747}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.4958588041799503}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.4487281666203801}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.4628387988151732}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.6082030539611206}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.4695809343771054}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.5292963972530413}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.6060156881899237}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.6614752019833315}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.7711283160288458}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.5451875372296747}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.6928100354416529}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.938415705643109}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.860147525998568}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.8840222531771742}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.9738234413319128}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.8274241952658944}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.9303406801266976}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.9157671942305898}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 0.9638837772046612}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"val_loss\", \"value\": 1.0345333550178433}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8573646154587051}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8663788273064278}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8832093371537479}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8595527509471479}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8935760225627897}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8669725989304085}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.872608745138364}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8807668652370195}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8578518130655303}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8904588884898533}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.884429251165986}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8323986424104226}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8577351729524915}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8684069755475833}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.863545538987374}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.877417788119338}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8778935343312512}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.867298553160866}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8676986799166928}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_weighted\", \"value\": 0.8706343696052897}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8273969279771379}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8451602051951018}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8706754195361591}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8441875347657711}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8808061574387948}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8556791579077642}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8614952300310472}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8689176535525341}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8467337078323696}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.875610801429232}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.87280379340137}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8141495807336984}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8472651605101656}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8530395351864412}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8441701346947824}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8607777231139554}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8633361055922624}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.851421950040113}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8504953152426699}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_macro\", \"value\": 0.8512319710813316}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.86022070415134}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8691539674198635}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.884393063583815}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8586442459274829}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8938518129269575}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8696794534944825}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8744088281660536}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.882291119285339}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8560168155543878}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8901734104046243}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.884393063583815}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.837099316868103}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8607461902259589}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8696794534944825}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8649500788229112}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8780872306883868}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8775617446137677}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8686284813452444}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8696794534944825}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 3, \"line type\": \"F1_score_micro\", \"value\": 0.8712559117183395}], \"data-024fc1542d6345d2c5b53edce4f727e8\": [{\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.6613166422471639}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.4101578309445274}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.3731523575953368}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.3511781552040992}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.3450505391405034}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.3232106246807937}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.2945421027734253}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.2835657860025491}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.2663345916521737}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.2407778916923777}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.2381528773165416}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.2155837053348072}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.1947525789316899}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.1846169877303089}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.1643365828455875}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.149213807995693}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.1317330167507212}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.1351674779537713}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.117747600726714}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"train_loss\", \"value\": 0.11477178847619}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.563256886003132}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.4948350787554093}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.4573092861609737}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.4260478577275267}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.4001301875613833}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.468371873807569}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.5239014649414457}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.4903722728701394}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.5475002329692855}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.5648295692414703}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.5513430054401275}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.5952566323572958}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.6978452879054562}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.7254927348455086}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.6998725984196136}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.7863674883137872}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.8608385830879908}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.8150464960474456}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.9735137195767348}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"val_loss\", \"value\": 0.8460306023367868}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8386624396013904}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8770358914864617}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8825018174980893}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8879883547471209}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8899042723009569}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8595726775213766}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8820997853996468}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8861843628355645}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8873582611306794}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8908037749541255}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8891526230464272}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8844550127621759}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8732399849244775}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8703402470497138}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8768811120821394}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8758412870292333}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8715859601715988}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8752551707826098}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.8551696928024564}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_weighted\", \"value\": 0.873529596495617}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8015932236467883}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8604994252402306}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8687915030757468}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8773664452813308}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8778866571336676}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8484178935895902}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8637998748472316}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8727069483680507}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8730368797807876}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8781053448407953}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8744396993174659}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8722878652900632}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8565581558457215}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8549655157748416}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8635465525928522}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8639673731567887}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8558320205016559}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8614762573267534}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8435660689978537}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_macro\", \"value\": 0.8566870448536691}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8444561219127693}, {\"epoch\": 2, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8775617446137677}, {\"epoch\": 3, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.882816605359958}, {\"epoch\": 4, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8885969521807673}, {\"epoch\": 5, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8896479243300053}, {\"epoch\": 6, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8628481345244351}, {\"epoch\": 7, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.882816605359958}, {\"epoch\": 8, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8870204939569102}, {\"epoch\": 9, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8885969521807673}, {\"epoch\": 10, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8917498686284814}, {\"epoch\": 11, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8896479243300053}, {\"epoch\": 12, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8854440357330531}, {\"epoch\": 13, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8733578560168156}, {\"epoch\": 14, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8702049395691014}, {\"epoch\": 15, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8775617446137677}, {\"epoch\": 16, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8754598003152917}, {\"epoch\": 17, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8702049395691014}, {\"epoch\": 18, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8749343142406726}, {\"epoch\": 19, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.858118759852864}, {\"epoch\": 20, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"BertForSequenceClassification\", \"hidden_dropout_prob\": 0.1, \"attention_probs_dropout_prob\": 0.1, \"table id\": 4, \"line type\": \"F1_score_micro\", \"value\": 0.8733578560168156}], \"data-f2247bd58ebdb2b9ff789266d08eff87\": [{\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"vinai/phobert-base\", \"hidden_dropout_prob\": 0.4, \"attention_probs_dropout_prob\": 0.1, \"table id\": 5, \"line type\": \"train_loss\", \"value\": 0.8445599699264201}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"vinai/phobert-base\", \"hidden_dropout_prob\": 0.4, \"attention_probs_dropout_prob\": 0.1, \"table id\": 5, \"line type\": \"val_loss\", \"value\": 0.5590339578215092}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"vinai/phobert-base\", \"hidden_dropout_prob\": 0.4, \"attention_probs_dropout_prob\": 0.1, \"table id\": 5, \"line type\": \"F1_score_weighted\", \"value\": 0.7909359442027981}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"vinai/phobert-base\", \"hidden_dropout_prob\": 0.4, \"attention_probs_dropout_prob\": 0.1, \"table id\": 5, \"line type\": \"F1_score_macro\", \"value\": 0.7612925350904449}, {\"epoch\": 1, \"batch_size\": 8, \"Ir\": 1e-05, \"eps\": 1e-08, \"pre_trained_model\": \"vinai/phobert-base\", \"hidden_dropout_prob\": 0.4, \"attention_probs_dropout_prob\": 0.1, \"table id\": 5, \"line type\": \"F1_score_micro\", \"value\": 0.7953913388955105}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.HConcatChart(...)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["#reviewType_Chart1_tuning\n","\n","model_compare_df = build_df__phobert_comparision(eval_df)\n","model_compare_chart= combined_graph(model_compare_df)\n","save(model_compare_chart, path_visualization+'reviewType_model_compare.png')\n","print('Model comparison chart is saved ,please check')\n","model_compare_chart\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":579},"executionInfo":{"elapsed":6630,"status":"ok","timestamp":1660755137487,"user":{"displayName":"suwasit wittawijugbbt","userId":"09267968935034910060"},"user_tz":-420},"id":"BrcR3x40jKxG","outputId":"64b7a665-9d45-4c82-f37e-5b993c90afa2"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARN Scale bindings are currently only supported for scales with unbinned, continuous domains.\n"]},{"name":"stdout","output_type":"stream","text":["The comparison chart is now ready..please check.\n"]},{"data":{"text/html":["\n","<div id=\"altair-viz-1331a211c8284f7c92cf90f639be20bd\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-1331a211c8284f7c92cf90f639be20bd\") {\n","      outputDiv = document.getElementById(\"altair-viz-1331a211c8284f7c92cf90f639be20bd\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 15, \"titleFontSize\": 15}}, \"layer\": [{\"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"algorithms\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"f1_score\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"algorithm_method\", \"type\": \"nominal\"}, \"y\": {\"field\": \"f1_score\", \"scale\": {\"domain\": [0, 1.1]}, \"type\": \"quantitative\"}}, \"selection\": {\"selector011\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}}, {\"mark\": {\"type\": \"text\", \"dy\": -10}, \"encoding\": {\"color\": {\"field\": \"algorithms\", \"type\": \"nominal\"}, \"text\": {\"field\": \"f1_score\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"f1_score\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"algorithm_method\", \"type\": \"nominal\"}, \"y\": {\"field\": \"f1_score\", \"scale\": {\"domain\": [0, 1.1]}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-b1a61b61e6ee6a7c3a4613ced0ea5d94\"}, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-b1a61b61e6ee6a7c3a4613ced0ea5d94\": [{\"algorithms\": \"random_forest\", \"accuracy\": 0.6523749474569147, \"precision\": 0.7263806608015959, \"recall\": 0.5096809297430014, \"f1_score\": 0.5067796835867253, \"data_method\": \"removed\", \"algorithm_method\": \"random_forest-removed\"}, {\"algorithms\": \"svm\", \"accuracy\": 0.7347625052543085, \"precision\": 0.7170620061401762, \"recall\": 0.667236773165918, \"f1_score\": 0.6842635480937423, \"data_method\": \"removed\", \"algorithm_method\": \"svm-removed\"}, {\"algorithms\": \"xgboost\", \"accuracy\": 0.6616225304749895, \"precision\": 0.710334047018604, \"recall\": 0.5334400361198398, \"f1_score\": 0.5437010817264748, \"data_method\": \"removed\", \"algorithm_method\": \"xgboost-removed\"}, {\"algorithms\": \"random_forest\", \"accuracy\": 0.7263191354100444, \"precision\": 0.8468515711800997, \"recall\": 0.7020591711813242, \"f1_score\": 0.6988772773547816, \"data_method\": \"upsampling\", \"algorithm_method\": \"random_forest-upsampling\"}, {\"algorithms\": \"svm\", \"accuracy\": 0.7263191354100444, \"precision\": 0.8468515711800997, \"recall\": 0.7020591711813242, \"f1_score\": 0.6988772773547816, \"data_method\": \"upsampling\", \"algorithm_method\": \"svm-upsampling\"}, {\"algorithms\": \"xgboost\", \"accuracy\": 0.7838525111252383, \"precision\": 0.8209252999796135, \"recall\": 0.7814167964464307, \"f1_score\": 0.7918331356915078, \"data_method\": \"upsampling\", \"algorithm_method\": \"xgboost-upsampling\"}, {\"algorithms\": \"random_forest\", \"accuracy\": 0.6248969497114591, \"precision\": 0.630024546733734, \"recall\": 0.3166337653353456, \"f1_score\": 0.3260682112758704, \"data_method\": \"all\", \"algorithm_method\": \"random_forest-all\"}, {\"algorithms\": \"svm\", \"accuracy\": 0.7300082440230833, \"precision\": 0.7522732276974643, \"recall\": 0.459502716866684, \"f1_score\": 0.49534910892141204, \"data_method\": \"all\", \"algorithm_method\": \"svm-all\"}, {\"algorithms\": \"xgboost\", \"accuracy\": 0.7040395713107996, \"precision\": 0.7797257726170954, \"recall\": 0.41931483619998106, \"f1_score\": 0.45594095161500536, \"data_method\": \"all\", \"algorithm_method\": \"xgboost-all\"}, {\"algorithms\": \"Phobert\", \"accuracy\": 0.8858868404322949, \"precision\": 0.8809417903374632, \"recall\": 0.8904097063284248, \"f1_score\": 0.8839762511939793, \"data_method\": \"upsampling\", \"algorithm_method\": \"Phobert-upsampling\"}, {\"algorithms\": \"Phobert\", \"accuracy\": 0.8860865910046238, \"precision\": 0.8775043155089017, \"recall\": 0.8560930052316573, \"f1_score\": 0.8656961990173627, \"data_method\": \"removed\", \"algorithm_method\": \"Phobert-removed\"}, {\"algorithms\": \"Phobert\", \"accuracy\": 0.8689200329760923, \"precision\": 0.6080245827988845, \"recall\": 0.6204020796254547, \"f1_score\": 0.6122196717020758, \"data_method\": \"all\", \"algorithm_method\": \"Phobert-all\"}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.LayerChart(...)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["#reviewType_Chart2_compare_traditional.\n","model_compare_chart = compare_tranditional()   \n","save(model_compare_chart, path_visualization+'reviewType_model_compare_traditional.png')\n","print('The comparison chart is now ready..please check.')\n","model_compare_chart"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"reviewType_notebooks_git.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}