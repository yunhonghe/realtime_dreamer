{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "10a7d69a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10a7d69a",
        "outputId": "c80ab908-3112-44cf-aa77-a903cb3f729a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount My Google Drive files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a099e3b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a099e3b6",
        "outputId": "562a58ac-22cb-4d45-a546-2100ba364ecf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "import xgboost as xgb\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "import seaborn as sns\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import altair as alt\n",
        "alt.renderers.enable('default')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Set current device\n",
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "Wv6zFkXY_JSw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "Wv6zFkXY_JSw",
        "outputId": "10d3300a-ba39-4a72-8554-37e0165c23e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6018, 4)\n",
            "positive    5250\n",
            "negative     499\n",
            "neutral      269\n",
            "Name: emotion, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-b9c579f90a094cc58f8a06e066ecbe54\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-b9c579f90a094cc58f8a06e066ecbe54\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-b9c579f90a094cc58f8a06e066ecbe54\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300, \"stroke\": null}, \"concat\": {\"spacing\": 15}, \"title\": {\"fontSize\": 12}}, \"vconcat\": [{\"data\": {\"name\": \"data-bdf253ef8bca8c922b84646dd329f190\"}, \"mark\": {\"type\": \"text\", \"color\": \"black\", \"dx\": 150, \"dy\": 0, \"size\": 15}, \"encoding\": {\"text\": {\"field\": \"text\", \"type\": \"nominal\"}}, \"height\": 20, \"width\": 140}, {\"data\": {\"name\": \"data-54c5c0db463870f1634fb3d75b24333e\"}, \"mark\": {\"type\": \"bar\", \"size\": 10}, \"encoding\": {\"color\": {\"field\": \"f1 score average type\", \"legend\": {\"direction\": \"horizontal\", \"labelColor\": \"black\", \"labelFontSize\": 10.5, \"orient\": \"bottom\", \"titleColor\": \"black\", \"titleFontSize\": 11}, \"scale\": {\"scheme\": \"redyellowgreen\"}, \"type\": \"nominal\"}, \"column\": {\"field\": \"f1 score average type\", \"sort\": [\"GaussianNB\", \"RandomForestClassifier\", \"dummy_clf_most_frequent\", \"LogisticRegression\", \"XGBClassifier\", \"dummy_clf_uniform\"], \"title\": \"\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"ML Classfier\", \"type\": \"nominal\"}, {\"field\": \"f1 score average type\", \"type\": \"nominal\"}, {\"field\": \"value\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"labelAngle\": -90}, \"field\": \"ML Classfier\", \"sort\": [\"GaussianNB\", \"RandomForestClassifier\", \"dummy_clf_most_frequent\", \"LogisticRegression\", \"XGBClassifier\", \"dummy_clf_uniform\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0, 1]}, \"title\": \"\", \"type\": \"quantitative\"}}, \"height\": 150, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 140}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-bdf253ef8bca8c922b84646dd329f190\": [{\"text\": \"Sentiment Analysis Supervised ML Model Evaluation\"}], \"data-54c5c0db463870f1634fb3d75b24333e\": [{\"ML Classfier\": \"GaussianNB\", \"f1 score average type\": \"F1_score_macro\", \"value\": 0.34448906738063356}, {\"ML Classfier\": \"RandomForestClassifier\", \"f1 score average type\": \"F1_score_macro\", \"value\": 0.33453376064140267}, {\"ML Classfier\": \"dummy_clf_most_frequent\", \"f1 score average type\": \"F1_score_macro\", \"value\": 0.3105590062111801}, {\"ML Classfier\": \"LogisticRegression\", \"f1 score average type\": \"F1_score_macro\", \"value\": 0.3105590062111801}, {\"ML Classfier\": \"XGBClassifier\", \"f1 score average type\": \"F1_score_macro\", \"value\": 0.3105590062111801}, {\"ML Classfier\": \"dummy_clf_uniform\", \"f1 score average type\": \"F1_score_macro\", \"value\": 0.2390332220641365}, {\"ML Classfier\": \"GaussianNB\", \"f1 score average type\": \"F1_score_micro\", \"value\": 0.8006644518272426}, {\"ML Classfier\": \"RandomForestClassifier\", \"f1 score average type\": \"F1_score_micro\", \"value\": 0.8687707641196013}, {\"ML Classfier\": \"dummy_clf_most_frequent\", \"f1 score average type\": \"F1_score_micro\", \"value\": 0.872093023255814}, {\"ML Classfier\": \"LogisticRegression\", \"f1 score average type\": \"F1_score_micro\", \"value\": 0.872093023255814}, {\"ML Classfier\": \"XGBClassifier\", \"f1 score average type\": \"F1_score_micro\", \"value\": 0.872093023255814}, {\"ML Classfier\": \"dummy_clf_uniform\", \"f1 score average type\": \"F1_score_micro\", \"value\": 0.3338870431893688}, {\"ML Classfier\": \"GaussianNB\", \"f1 score average type\": \"F1_score_weighted\", \"value\": 0.787201964002188}, {\"ML Classfier\": \"RandomForestClassifier\", \"f1 score average type\": \"F1_score_weighted\", \"value\": 0.8167865246262856}, {\"ML Classfier\": \"dummy_clf_most_frequent\", \"f1 score average type\": \"F1_score_weighted\", \"value\": 0.8125090278780875}, {\"ML Classfier\": \"LogisticRegression\", \"f1 score average type\": \"F1_score_weighted\", \"value\": 0.8125090278780875}, {\"ML Classfier\": \"XGBClassifier\", \"f1 score average type\": \"F1_score_weighted\", \"value\": 0.8125090278780875}, {\"ML Classfier\": \"dummy_clf_uniform\", \"f1 score average type\": \"F1_score_weighted\", \"value\": 0.4298247951638138}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.VConcatChart(...)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read reviews label dataset\n",
        "train_review_df = pd.read_excel(f'/content/drive/MyDrive/Realtime Dreamer/train reviews.xlsx',engine='openpyxl',sheet_name='train', skiprows=0)\n",
        "print(train_review_df.shape)\n",
        "print(train_review_df['emotion'].value_counts())\n",
        "\n",
        "train_review_df.head()\n",
        "\n",
        "# Create dictionary for class labels\n",
        "label_dict = {'positive':2,'neutral': 1, 'negative':0}\n",
        "label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "def add_label_to_df(df):\n",
        "\n",
        "    \"\"\"Create function add_label_to_df to add label to reviews label dataset.\"\"\"  \n",
        "\n",
        "\n",
        "    df['label'] = df['emotion'].replace(label_dict)\n",
        "\n",
        "    return df\n",
        "\n",
        " \n",
        "\n",
        "def data_split(df):\n",
        "\n",
        "    \"\"\"\n",
        "    Create function data_split to \n",
        "    1. splict review lable dataset into train and validation data. \n",
        "    2. stratify the data to handle imbalance class issue.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    df=add_label_to_df(df)\n",
        "    X_train, X_val1, y_train, y_val1 = train_test_split(df.index.values,\n",
        "    df['label'].values,\n",
        "    test_size=0.20,\n",
        "    random_state=RANDOM_SEED,\n",
        "    stratify=df['label'].values)\n",
        "    \n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val1,\n",
        "                                                    y_val1,\n",
        "                                                    test_size=0.50,\n",
        "                                                    random_state=RANDOM_SEED,\n",
        "                                                    stratify=y_val1)\n",
        "  \n",
        "    return X_train, X_val, X_test,  y_train, y_val, y_test\n",
        "\n",
        "\n",
        "def set_data_category_in_df(df):\n",
        "  \n",
        "    \"\"\"Create function set_data_category_in_df to set data categary inside the reviews label data.\"\"\"\n",
        "\n",
        "\n",
        "    X_train, X_val, X_test,  y_train, y_val, y_test =data_split(df)    \n",
        "    df['data_category'] = ['unset']*df.shape[0]\n",
        "    df.loc[X_train, 'data_category'] = 'train'\n",
        "    df.loc[X_val, 'data_category'] = 'val'\n",
        "    df.loc[X_test, 'data_category'] = 'test'\n",
        "  \n",
        "    return df\n",
        "\n",
        "def vectorize_train_val_test_data(vec,df,col):\n",
        "\n",
        "    \"\"\"Create function vectorize_train_val_test_data to vectorize train and validation dataset\"\"\"\n",
        "    \n",
        "\n",
        "    X_train    = vec.fit_transform(df[df.data_category=='train'][col].values )\n",
        "    X_val  = vec.transform(df[df.data_category=='val'][col].values)\n",
        "    X_test = vec.transform(df[df.data_category=='test'][col].values)\n",
        "    \n",
        "    return X_train,X_val,X_test\n",
        "\n",
        "def calcualte_F1_scores(vec,clf,X_train,y_train,X_val,y_val):\n",
        "\n",
        "    \"\"\"Create function calcualte_F1_scores to calcuate 1_score_macro,f1_score_micro,f1_score_weighted.\"\"\"\n",
        "  \n",
        "  \n",
        "    if clf == gnb:\n",
        "        clf = clf.fit(X_train.toarray(), y_train)\n",
        "        predicted_y = clf.predict(X_val.toarray())\n",
        "    else:  \n",
        "        clf = clf.fit(X_train, y_train)    \n",
        "        predicted_y = clf.predict(X_val)\n",
        "        \n",
        "    f1_score_macro = f1_score(y_val,predicted_y, average='macro')\n",
        "    f1_score_micro = f1_score(y_val,predicted_y, average='micro')\n",
        "    f1_score_weighted = f1_score(y_val,predicted_y, average='weighted')\n",
        "\n",
        "    return f1_score_macro,f1_score_micro,f1_score_weighted\n",
        "\n",
        "def make_scores_dataset(vec):\n",
        "    \n",
        "    \"\"\"\n",
        "    Create function make_scores_dataset to \n",
        "    generate dataframe scores_df with F1_score_macro, F1_score_micro and F1_score_weighted.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    f1_macro_list=[]\n",
        "    f1_micro_list=[]\n",
        "    f1_weighted_list=[]\n",
        "\n",
        "    for clf in clf_list:\n",
        "        f1_macro,f1_micro,f1_weighted =calcualte_F1_scores(vec,clf,X_train,y_train,X_val,y_val)\n",
        "        f1_macro_list.append(f1_macro)\n",
        "        f1_micro_list.append(f1_micro)\n",
        "        f1_weighted_list.append(f1_weighted)\n",
        "\n",
        "    scores_df=pd.DataFrame()\n",
        "    scores_df['ML Classfier']=clf_name_list\n",
        "    scores_df['F1_score_macro']=f1_macro_list\n",
        "    scores_df['F1_score_micro']=f1_micro_list\n",
        "    scores_df['F1_score_weighted']=f1_weighted_list\n",
        "    scores_df.sort_values(by=['F1_score_macro','F1_score_micro','F1_score_weighted'],ascending=False, inplace=True)\n",
        "\n",
        "    return scores_df\n",
        "\n",
        "# Initiate TfidfVectorizer to convert a collection of review records to a matrix of TF-IDF features.\n",
        "vec = TfidfVectorizer(ngram_range=(1,3))\n",
        "\n",
        "# Splict review lable dataset into train and validation data\n",
        "_, _, _, y_train, y_val, y_test = data_split(train_review_df)\n",
        "\n",
        "# Set data categary inside the reviews label data\n",
        "emotion_df = set_data_category_in_df(train_review_df)\n",
        "\n",
        "# Vectorize train and validation dataset\n",
        "X_train, X_val, X_test = vectorize_train_val_test_data(vec, emotion_df, 'Review Content')\n",
        "\n",
        "# Initiate DummyClassifier, set strategy=\"uniform\"\n",
        "dummy_clf_uni = DummyClassifier(strategy=\"uniform\", random_state=RANDOM_SEED)\n",
        "\n",
        "# Initiate DummyClassifier, set strategy=\"most_frequent\"\n",
        "dummy_clf_mfrq = DummyClassifier(strategy=\"most_frequent\", random_state=RANDOM_SEED)\n",
        "\n",
        "# Initiate LogisticRegression, set solver='lbfgs',multi_class='auto'\n",
        "lr_clf = LogisticRegression(random_state=RANDOM_SEED, solver='lbfgs',multi_class='auto',n_jobs=-1)\n",
        "\n",
        "# Initiate RandomForestClassifier\n",
        "rf_clf = RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=-1)\n",
        "\n",
        "# Initiate GaussianNB\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Initiate XGBClassifier\n",
        "xgb_clf = xgb.sklearn.XGBClassifier()\n",
        "\n",
        "# Create clf_list for ML classifier\n",
        "clf_list = [dummy_clf_uni, dummy_clf_mfrq, lr_clf, rf_clf, gnb, xgb_clf]\n",
        "\n",
        "# Create clf_name_list for ML classifier names\n",
        "clf_name_list = ['dummy_clf_uniform', 'dummy_clf_most_frequent', 'LogisticRegression',\n",
        "                 'RandomForestClassifier', 'GaussianNB', 'XGBClassifier']\n",
        "\n",
        "# Create make_scores_df with F1_score_macro, F1_score_micro and F1_score_weighted\n",
        "make_scores_df = make_scores_dataset(vec)\n",
        "\n",
        "# Create sorted list sorted_clf with sorted name of ML classifers sorted by F1 score macro descending.\n",
        "sorted_clf = list(make_scores_df['ML Classfier'])\n",
        "\n",
        "# Create make_scores_df_long dataframe as long form of make_scores_df.\n",
        "make_scores_df_long = pd.melt(make_scores_df, \n",
        "                              id_vars=['ML Classfier'], \n",
        "                              value_vars=['F1_score_macro','F1_score_micro','F1_score_weighted'],\n",
        "                              var_name=['f1 score average type'])\n",
        "\n",
        "# Create graph for ML classifer model evaluation.\n",
        "graph = alt.Chart(make_scores_df_long).mark_bar(size=10).encode(\n",
        "        x = alt.X('ML Classfier:N', sort=sorted_clf, axis=alt.Axis(labelAngle=-90)),\n",
        "        y = alt.Y('value:Q', title='',scale=alt.Scale(domain=(0,1))),\n",
        "        color = alt.Color('f1 score average type:N',\n",
        "                          scale=alt.Scale(scheme='redyellowgreen'),\n",
        "                          legend=alt.Legend(orient='bottom',\n",
        "                                            titleFontSize=11,\n",
        "                                            titleColor='black',\n",
        "                                            labelFontSize=10.5,\n",
        "                                            labelColor='black',\n",
        "                                            direction='horizontal')),\n",
        "        column=alt.Column('f1 score average type:N',title='',sort=sorted_clf),\n",
        "        tooltip = ['ML Classfier',\n",
        "                   'f1 score average type',\n",
        "                   'value']\n",
        "        ).interactive(\n",
        "        ).properties(width=140,\n",
        "                     height=150\n",
        "                     )\n",
        "\n",
        "title = alt.Chart({\"values\": [{\"text\": \"Sentiment Analysis Supervised ML Model Evaluation\"}]}\n",
        "                      ).mark_text(size=15, dx=150, dy=0, color=\"black\"\n",
        "                      ).encode(text='text:N'\n",
        "                      ).properties(width=140,height=20)\n",
        "\n",
        "chart = (title & graph\n",
        "        ).configure_view(stroke=None\n",
        "        ).configure_concat(spacing=15\n",
        "        ).configure_title(fontSize=12)\n",
        "\n",
        "chart"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Sentiment Analysis Supervised Machine Learning-colab Aug 16 2022.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
